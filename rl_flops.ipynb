{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "import multiprocessing as mp\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "import copy\n",
    "\n",
    "from src.rl_environment import Environment\n",
    "from src.graph_model import get_peo\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print (use_cuda)\n",
    "\n",
    "def to_tensor(*args, **kwargs):\n",
    "    return torch.Tensor(*args, **kwargs).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-23 16:37:21,483- INFO•\treading file inst_2x2_7_0.txt\n",
      "2018-11-23 16:37:21,491- INFO•\tThere are 4 qubits in circuit\n",
      "2018-11-23 16:37:21,493- INFO•\tGenerated graph with 10 nodes and 22 edges\n",
      "2018-11-23 16:37:21,494- INFO•\tlast index contains from [9, 2, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "env = Environment('inst_2x2_7_0.txt', square_index=True)\n",
    "state_shape = (15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    probs = np.ones(15) / 15\n",
    "    mask = env.available_actions\n",
    "    probs = probs * mask\n",
    "    probs = probs / probs.sum()\n",
    "    \n",
    "    action = np.random.choice(15, p=probs)\n",
    "    s, cost, done = env.step(action)\n",
    "    plt.imshow(s)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sequential import SequentialNet, name2nn\n",
    "from models.utils import create_optimal_inner_init, out_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(\n",
    "            self, output_size,\n",
    "            conv_hiddens, linear_hiddens,\n",
    "            conv_kwargs=None,\n",
    "            state_shape=[15, 15], num_channels=1,\n",
    "            activation_fn=nn.ReLU, norm_fn=None, bias=True):\n",
    "        super().__init__()\n",
    "        activation_fn = name2nn(activation_fn)\n",
    "        norm_fn = name2nn(norm_fn)\n",
    "        self.input_shape = [num_channels] + state_shape\n",
    "        default_conv_kwargs = {\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 2,\n",
    "            \"padding\": 0\n",
    "        }\n",
    "        conv_kwargs = conv_kwargs or default_conv_kwargs\n",
    "\n",
    "        def conv_fn(f_in, f_out, bias=True):\n",
    "            return nn.Conv2d(f_in, f_out, bias=bias, **conv_kwargs)\n",
    "\n",
    "        self.conv_net = SequentialNet(\n",
    "            hiddens=[num_channels] + conv_hiddens,\n",
    "            layer_fn=conv_fn,\n",
    "            activation_fn=activation_fn,\n",
    "            norm_fn=None,\n",
    "            bias=bias)\n",
    "        hw = state_shape[0]\n",
    "        padding = conv_kwargs.get(\"padding\", 0)\n",
    "        ksize = conv_kwargs[\"kernel_size\"]\n",
    "        stride = conv_kwargs.get(\"stride\", 1)\n",
    "        for i in range(len(conv_hiddens)):\n",
    "            hw = (hw + 2 * padding - (ksize - 1) - 1) // stride + 1\n",
    "        linear_input_size = conv_hiddens[-1] * hw ** 2\n",
    "        self.linear_net = SequentialNet(\n",
    "            hiddens=[linear_input_size] + linear_hiddens,\n",
    "            layer_fn=nn.Linear,\n",
    "            activation_fn=activation_fn,\n",
    "            norm_fn=None,\n",
    "            bias=bias)\n",
    "        self.policy_net = SequentialNet(\n",
    "            hiddens=[linear_hiddens[-1], output_size],\n",
    "            layer_fn=nn.Linear,\n",
    "            activation_fn=None,\n",
    "            norm_fn=None,\n",
    "            bias=True)\n",
    "        inner_init = create_optimal_inner_init(nonlinearity=activation_fn)\n",
    "        self.conv_net.apply(inner_init)\n",
    "        self.linear_net.apply(inner_init)\n",
    "        self.policy_net.apply(out_init)\n",
    "        \n",
    "    def forward(self, states):\n",
    "        if len(states.shape) == 3:\n",
    "            states = states[..., None]\n",
    "        x = states.permute(0, 3, 1, 2)\n",
    "        x = self.conv_net(x).view(states.shape[0], -1)\n",
    "        x = self.linear_net(x)\n",
    "        logits = self.policy_net(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(ConvNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def forward(self, states, mask, with_dist=False):\n",
    "        logits = super().forward(states)\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        probs = (probs + 1e-6) * mask\n",
    "        #probs = probs * mask\n",
    "        probs = probs / probs.sum(dim=-1)[..., None]\n",
    "        dist = torch.distributions.Categorical(probs=probs)\n",
    "        action = dist.sample()\n",
    "        if with_dist:\n",
    "            return action, dist\n",
    "        return action\n",
    "\n",
    "\n",
    "class Critic(ConvNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def forward(self, states, with_log_pi=False):\n",
    "        values = super().forward(states)\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(env, actor):\n",
    "    states, actions, masks, rewards, dones = [], [], [], [], []\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    worst_cost = 0\n",
    "    \n",
    "    while not done:\n",
    "        states.append(s.tolist())\n",
    "        \n",
    "        mask = env.available_actions.copy()\n",
    "\n",
    "        a, dist = actor.forward(\n",
    "            to_tensor(s[None, :, :, None]),\n",
    "            mask=to_tensor(mask[None, :]),\n",
    "            with_dist=True)\n",
    "        a = a.cpu().detach().numpy()[0]\n",
    "\n",
    "        s, r, done = env.step(a)\n",
    "        \n",
    "        worst_cost = max(worst_cost, r)\n",
    "        \n",
    "        if done:\n",
    "            reward = -worst_cost\n",
    "        else:\n",
    "            reward = 0\n",
    "        \n",
    "        actions.append(a)\n",
    "        masks.append(mask.tolist())\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "\n",
    "    return states, actions, masks, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = (15, 15)\n",
    "conv_hiddens=[32, 64, 64]\n",
    "linear_hiddens = [256, 128]\n",
    "\n",
    "actor = Actor(\n",
    "    output_size=15,\n",
    "    conv_hiddens=conv_hiddens,\n",
    "    linear_hiddens=linear_hiddens).to(device) \n",
    "critic = Critic(\n",
    "    output_size=1,\n",
    "    conv_hiddens=conv_hiddens,\n",
    "    linear_hiddens=linear_hiddens).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferDataset(Dataset):\n",
    "    def __init__(self, state_shape, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.len = 0\n",
    "        self.pointer = 0\n",
    "        \n",
    "        self.states = np.empty((self.max_size,) + state_shape, dtype=np.float32)\n",
    "        self.actions = np.empty((self.max_size,), dtype=np.int32)\n",
    "        self.masks = np.empty((self.max_size, 15), dtype=np.int32)\n",
    "        self.returns = np.empty((self.max_size,), dtype=np.float32)\n",
    "        self.values = np.empty((self.max_size,), dtype=np.float32)\n",
    "        self.advantages = np.empty((self.max_size,), dtype=np.float32)\n",
    "        self.log_pis = np.empty((self.max_size,), dtype=np.float32)\n",
    "\n",
    "    def push_episode(self, episode):\n",
    "        states, actions, masks, ret, val, adv, log_pi = episode\n",
    "        episode_len = len(actions)\n",
    "        self.len = min(self.len + episode_len, self.max_size)\n",
    "        indices = np.arange(\n",
    "            self.pointer, self.pointer + episode_len) % self.max_size\n",
    "        self.states[indices] = states\n",
    "        self.actions[indices] = actions\n",
    "        self.masks[indices] = masks\n",
    "        self.returns[indices] = ret\n",
    "        self.values[indices] = val\n",
    "        self.advantages[indices] = adv\n",
    "        self.log_pis[indices] = log_pi\n",
    "        self.pointer = (self.pointer + episode_len) % self.max_size\n",
    "\n",
    "    def rescale_advantages(self):\n",
    "        adv_centered = self.advantages[:self.len] - self.advantages[:self.len].mean()\n",
    "        self.advantages[:self.len] = adv_centered / (self.advantages[:self.len].std() + 1e-6)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dct = {\n",
    "            \"state\": self.states[index],\n",
    "            \"action\": self.actions[index].astype(np.float32),\n",
    "            \"mask\": self.masks[index].astype(np.float32),\n",
    "            \"return\": self.returns[index],\n",
    "            \"value\": self.values[index],\n",
    "            \"advantage\": self.advantages[index],\n",
    "            \"log_pi\": self.log_pis[index]\n",
    "        }\n",
    "        return dct\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "        \n",
    "class BufferSampler(Sampler):\n",
    "    def __init__(self, buffer, num_mini_epochs):\n",
    "        super().__init__(None)\n",
    "        self.buffer = buffer\n",
    "        self.num_mini_epochs = num_mini_epochs\n",
    "        buffer_len = len(self.buffer)\n",
    "        self.len = buffer_len * num_mini_epochs\n",
    "\n",
    "        indices = []\n",
    "        for i in range(num_mini_epochs):\n",
    "            idx = np.arange(buffer_len)\n",
    "            np.random.shuffle(idx)\n",
    "            indices.append(idx)\n",
    "        self.indices = np.concatenate(indices)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gamma_matrix(tau, matrix_size):\n",
    "    \"\"\"\n",
    "    Matrix of the following form\n",
    "    --------------------\n",
    "    1     y   y^2    y^3\n",
    "    0     1     y    y^2\n",
    "    0     0     1      y\n",
    "    0     0     0      1\n",
    "    --------------------\n",
    "    for fast gae calculation\n",
    "    \"\"\"\n",
    "    i = np.arange(matrix_size)\n",
    "    j = np.arange(matrix_size)\n",
    "    pow_ = i[None, :] - j[:, None]\n",
    "    mat = np.power(tau, pow_) * (pow_ >= 0)\n",
    "    return mat\n",
    "\n",
    "\n",
    "class PPO_GAE:\n",
    "    def __init__(\n",
    "            self,\n",
    "            actor, critic,\n",
    "            gamma, gae_lambda=0.95,\n",
    "            clip_eps=0.2,\n",
    "            episode_len=1000,\n",
    "            minibatch_size=32,\n",
    "            num_mini_epochs=10,\n",
    "            use_value_clipping=False,\n",
    "            entropy_reg_coefficient=0.):\n",
    "        self._device = device\n",
    "\n",
    "        self.actor = actor.to(self._device)\n",
    "        self.critic = critic.to(self._device)\n",
    "        \n",
    "        self.actor_optimizer = optim.Adam(\n",
    "            self.actor.parameters(), lr=lr)\n",
    "        self.critic_optimizer = optim.Adam(\n",
    "            self.critic.parameters(), lr=lr)\n",
    "\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.gamma = gamma\n",
    "        self.clip_eps = clip_eps\n",
    "        self.episode_len = episode_len\n",
    "        self.num_mini_epochs = num_mini_epochs\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.use_value_clipping = use_value_clipping\n",
    "        self.entropy_reg_coefficient = entropy_reg_coefficient\n",
    "\n",
    "        self.gam_lam_matrix = create_gamma_matrix(\n",
    "            self.gamma * gae_lambda, episode_len)\n",
    "        self.gam_matrix = create_gamma_matrix(\n",
    "            self.gamma, episode_len)\n",
    "        \n",
    "    def to_tensor(self, *args, **kwargs):\n",
    "        return torch.Tensor(*args, **kwargs).to(self._device)\n",
    "\n",
    "    def evaluate_episode(self, states, actions, masks, rewards):\n",
    "        states = self.to_tensor(states)\n",
    "        actions = self.to_tensor(actions)\n",
    "        masks = self.to_tensor(masks)\n",
    "        rewards = np.array(rewards)\n",
    "\n",
    "        ep_len = rewards.shape[0]\n",
    "        values = torch.zeros((ep_len + 1, 1)).to(self._device)\n",
    "        values[:ep_len] = self.critic(states)\n",
    "        values = values.detach().cpu().numpy().reshape(-1)\n",
    "        \n",
    "        _, dist = self.actor(states, masks, with_dist=True)\n",
    "        log_pis = dist.log_prob(actions)\n",
    "        log_pis = log_pis.detach().cpu().numpy().reshape(-1)\n",
    "        \n",
    "        deltas = rewards + self.gamma * values[1:] - values[:-1]\n",
    "        advantages = np.dot(self.gam_lam_matrix[:ep_len, :ep_len], deltas)\n",
    "        returns = np.dot(self.gam_matrix[:ep_len, :ep_len], rewards)\n",
    "\n",
    "        return [returns, values[:ep_len], advantages, log_pis]\n",
    "\n",
    "    def train(self, batch):\n",
    "        states, actions, masks, returns, values, advantages, log_pis = \\\n",
    "            batch[\"state\"], batch[\"action\"], batch[\"mask\"], batch[\"return\"], \\\n",
    "            batch[\"value\"], batch[\"advantage\"], batch[\"log_pi\"]\n",
    "\n",
    "        states = self.to_tensor(states)\n",
    "        actions = self.to_tensor(actions)\n",
    "        masks = self.to_tensor(masks)\n",
    "        returns = self.to_tensor(returns)\n",
    "        old_values = self.to_tensor(values)\n",
    "        advantages = self.to_tensor(advantages)\n",
    "        old_log_pi = self.to_tensor(log_pis)\n",
    "\n",
    "        values_t = self.critic(states).squeeze()\n",
    "        if self.use_value_clipping:\n",
    "            values_clip = old_values + torch.clamp(\n",
    "                values_t - old_values, -self.clip_eps, self.clip_eps)\n",
    "            val_loss1 = (values_t - returns).pow(2)\n",
    "            val_loss2 = (values_clip - returns).pow(2)\n",
    "            value_loss = 0.5 * torch.max(val_loss1, val_loss2).mean()\n",
    "        else:\n",
    "            value_loss = 0.5 * (values_t - returns).pow(2).mean()\n",
    "\n",
    "        # actor loss\n",
    "        _, dist = self.actor(states, masks, with_dist=True)\n",
    "        log_pi = dist.log_prob(actions)\n",
    "\n",
    "        ratio = torch.exp(log_pi - old_log_pi)\n",
    "        surr1 = advantages * ratio\n",
    "        surr2 = advantages * torch.clamp(\n",
    "            ratio, 1.0 - self.clip_eps, 1.0 + self.clip_eps)\n",
    "        policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "        entropy = -(torch.exp(log_pi) * log_pi).mean()\n",
    "        entropy_reg = self.entropy_reg_coefficient * entropy\n",
    "        policy_loss = policy_loss + entropy_reg\n",
    "\n",
    "        # actor update\n",
    "        self.actor_update(policy_loss)\n",
    "        # critic update\n",
    "        self.critic_update(value_loss)\n",
    "\n",
    "        metrics = {\n",
    "            \"loss_actor\": policy_loss.item(),\n",
    "            \"loss_critic\": value_loss.item()\n",
    "        }\n",
    "        return metrics\n",
    "        \n",
    "    def actor_update(self, loss):\n",
    "        self.actor.zero_grad()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "    def critic_update(self, loss):\n",
    "        self.critic.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.critic_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "lr = 1e-3\n",
    "\n",
    "num_mini_epochs = 6\n",
    "minibatch_size = 500\n",
    "\n",
    "state_shape = (15, 15)\n",
    "conv_hiddens=[64, 64]\n",
    "linear_hiddens = [128, 128]\n",
    "\n",
    "actor = Actor(\n",
    "    output_size=15,\n",
    "    conv_hiddens=conv_hiddens,\n",
    "    linear_hiddens=linear_hiddens).to(device) \n",
    "critic = Critic(\n",
    "    output_size=1,\n",
    "    conv_hiddens=conv_hiddens,\n",
    "    linear_hiddens=linear_hiddens).to(device)\n",
    "\n",
    "algo = PPO_GAE(\n",
    "    actor, critic,\n",
    "    gamma=0.99, gae_lambda=0.95,\n",
    "    minibatch_size=minibatch_size,\n",
    "    num_mini_epochs=num_mini_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.024126710147053625\n",
      "Critic loss:         9039.743133544922\n",
      "Average reward:      -146.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03439220520279681\n",
      "Critic loss:         3580.3063049316406\n",
      "Average reward:      -151.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037231347040991146\n",
      "Critic loss:         2446.549830118815\n",
      "Average reward:      -146.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04185892747288259\n",
      "Critic loss:         2603.649586995443\n",
      "Average reward:      -149.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041647211202265076\n",
      "Critic loss:         1534.5951182047527\n",
      "Average reward:      -142.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04683079706349721\n",
      "Critic loss:         1742.9422149658203\n",
      "Average reward:      -143.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.05047644968969204\n",
      "Critic loss:         1089.5341313680012\n",
      "Average reward:      -130.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04774858839421844\n",
      "Critic loss:         1227.486587524414\n",
      "Average reward:      -132.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.043252087042977415\n",
      "Critic loss:         1110.4137802124023\n",
      "Average reward:      -130.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.050101033033570275\n",
      "Critic loss:         1228.3930791219075\n",
      "Average reward:      -134.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.049302687315503135\n",
      "Critic loss:         1208.976224263509\n",
      "Average reward:      -127.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04644135304260999\n",
      "Critic loss:         1087.8780364990234\n",
      "Average reward:      -123.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.043752245022915304\n",
      "Critic loss:         1341.1665445963542\n",
      "Average reward:      -130.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.048942129709757864\n",
      "Critic loss:         1047.3375905354817\n",
      "Average reward:      -120.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.051342921797186136\n",
      "Critic loss:         1075.2405344645183\n",
      "Average reward:      -126.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04244750334570805\n",
      "Critic loss:         899.3468373616537\n",
      "Average reward:      -116.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04412516185160106\n",
      "Critic loss:         993.0251541137695\n",
      "Average reward:      -117.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.050057914321466036\n",
      "Critic loss:         765.8596038818359\n",
      "Average reward:      -116.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.047516576746905535\n",
      "Critic loss:         766.5176188151041\n",
      "Average reward:      -116.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04855535179376602\n",
      "Critic loss:         741.7211100260416\n",
      "Average reward:      -116.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04055878584889191\n",
      "Critic loss:         937.7671661376953\n",
      "Average reward:      -116.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041055892050887145\n",
      "Critic loss:         578.3619740804037\n",
      "Average reward:      -110.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03716060428026443\n",
      "Critic loss:         619.4142532348633\n",
      "Average reward:      -112.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0408924072762602\n",
      "Critic loss:         714.9540685017904\n",
      "Average reward:      -111.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03273206232552184\n",
      "Critic loss:         606.4878896077474\n",
      "Average reward:      -109.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038040747245152794\n",
      "Critic loss:         592.5256601969401\n",
      "Average reward:      -110.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03162527251212547\n",
      "Critic loss:         855.3538411458334\n",
      "Average reward:      -110.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03590956748909472\n",
      "Critic loss:         643.120859781901\n",
      "Average reward:      -111.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032045385694497476\n",
      "Critic loss:         585.9744644165039\n",
      "Average reward:      -110.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029881348775234073\n",
      "Critic loss:         820.4742685953776\n",
      "Average reward:      -113.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035694157083829246\n",
      "Critic loss:         447.6726989746094\n",
      "Average reward:      -100.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035030893307218015\n",
      "Critic loss:         557.7294629414877\n",
      "Average reward:      -111.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03329672661554165\n",
      "Critic loss:         601.8058166503906\n",
      "Average reward:      -108.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034728490902731814\n",
      "Critic loss:         547.2120196024576\n",
      "Average reward:      -107.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02860957970066617\n",
      "Critic loss:         620.1139488220215\n",
      "Average reward:      -104.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029545415095829714\n",
      "Critic loss:         472.19424057006836\n",
      "Average reward:      -103.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02673013805663989\n",
      "Critic loss:         476.6705805460612\n",
      "Average reward:      -104.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026746171361689147\n",
      "Critic loss:         610.0821278889974\n",
      "Average reward:      -105.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034841632179450244\n",
      "Critic loss:         468.13954671223956\n",
      "Average reward:      -104.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035547068468683087\n",
      "Critic loss:         534.2469940185547\n",
      "Average reward:      -104.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03281089387019165\n",
      "Critic loss:         366.6821009318034\n",
      "Average reward:      -101.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03456063906196505\n",
      "Critic loss:         421.29575475056964\n",
      "Average reward:      -102.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03333299021869607\n",
      "Critic loss:         673.6419245402018\n",
      "Average reward:      -104.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033995649515418336\n",
      "Critic loss:         616.7099444071451\n",
      "Average reward:      -106.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032941253875227026\n",
      "Critic loss:         438.6963589986165\n",
      "Average reward:      -102.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03224956186992737\n",
      "Critic loss:         530.5581169128418\n",
      "Average reward:      -103.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.02911065313128347\n",
      "Critic loss:         530.9786313374838\n",
      "Average reward:      -103.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0361367110235733\n",
      "Critic loss:         476.1509208679199\n",
      "Average reward:      -101.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031191348334080733\n",
      "Critic loss:         514.1264101664225\n",
      "Average reward:      -104.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025039914403654013\n",
      "Critic loss:         563.5767720540365\n",
      "Average reward:      -103.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02675776632774311\n",
      "Critic loss:         652.6405537923177\n",
      "Average reward:      -104.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03414037784386892\n",
      "Critic loss:         290.2973569234212\n",
      "Average reward:      -98.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031231557698144268\n",
      "Critic loss:         502.89899826049805\n",
      "Average reward:      -103.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028371933003654703\n",
      "Critic loss:         564.7382736206055\n",
      "Average reward:      -101.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034478244750062004\n",
      "Critic loss:         619.9901606241862\n",
      "Average reward:      -105.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02816072521576037\n",
      "Critic loss:         454.788277943929\n",
      "Average reward:      -102.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036916023159089185\n",
      "Critic loss:         425.85780080159503\n",
      "Average reward:      -102.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03248157935255828\n",
      "Critic loss:         387.66778055826825\n",
      "Average reward:      -99.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033243239197569587\n",
      "Critic loss:         475.55259958902997\n",
      "Average reward:      -101.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03135447562090121\n",
      "Critic loss:         497.0140126546224\n",
      "Average reward:      -103.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035229406164338194\n",
      "Critic loss:         436.04302469889325\n",
      "Average reward:      -101.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03365435100325461\n",
      "Critic loss:         476.3534990946452\n",
      "Average reward:      -98.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032518409068870824\n",
      "Critic loss:         414.5980809529622\n",
      "Average reward:      -97.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033393962406989885\n",
      "Critic loss:         433.6416867574056\n",
      "Average reward:      -101.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03455655622140815\n",
      "Critic loss:         336.0047556559245\n",
      "Average reward:      -98.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032231187379996605\n",
      "Critic loss:         413.1575406392415\n",
      "Average reward:      -100.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023012920981273055\n",
      "Critic loss:         421.8181317647298\n",
      "Average reward:      -98.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034155729527507596\n",
      "Critic loss:         360.82894643147785\n",
      "Average reward:      -98.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03242316223137701\n",
      "Critic loss:         388.74639383951825\n",
      "Average reward:      -100.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03182126581668854\n",
      "Critic loss:         561.3227602640787\n",
      "Average reward:      -102.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0335529570778211\n",
      "Critic loss:         428.12267684936523\n",
      "Average reward:      -97.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03500493763325115\n",
      "Critic loss:         529.6306838989258\n",
      "Average reward:      -102.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034567292352827884\n",
      "Critic loss:         397.02579498291016\n",
      "Average reward:      -97.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0302289577278619\n",
      "Critic loss:         473.04085032145184\n",
      "Average reward:      -97.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026884198693248134\n",
      "Critic loss:         494.1096076965332\n",
      "Average reward:      -97.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02591786431245661\n",
      "Critic loss:         549.1796747843424\n",
      "Average reward:      -97.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03470734514121432\n",
      "Critic loss:         345.0433044433594\n",
      "Average reward:      -95.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023537645310473938\n",
      "Critic loss:         488.04105377197266\n",
      "Average reward:      -101.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03563599045931672\n",
      "Critic loss:         492.40346654256183\n",
      "Average reward:      -99.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035246700746938586\n",
      "Critic loss:         538.2075576782227\n",
      "Average reward:      -100.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029785484188323608\n",
      "Critic loss:         569.9064242045084\n",
      "Average reward:      -96.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029157997128398467\n",
      "Critic loss:         472.5910415649414\n",
      "Average reward:      -95.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0358255555620417\n",
      "Critic loss:         290.72689692179364\n",
      "Average reward:      -93.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03697676058315361\n",
      "Critic loss:         423.9341735839844\n",
      "Average reward:      -97.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039508147950982675\n",
      "Critic loss:         332.4142074584961\n",
      "Average reward:      -95.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03925580906313068\n",
      "Critic loss:         272.61302439371747\n",
      "Average reward:      -93.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034480886895228956\n",
      "Critic loss:         377.3315086364746\n",
      "Average reward:      -95.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0383670546192055\n",
      "Critic loss:         364.6124738057454\n",
      "Average reward:      -95.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03388048016828785\n",
      "Critic loss:         461.69468943277997\n",
      "Average reward:      -98.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035456251446400223\n",
      "Critic loss:         317.65271759033203\n",
      "Average reward:      -94.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03720606532685148\n",
      "Critic loss:         497.5986785888672\n",
      "Average reward:      -102.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03356573711304615\n",
      "Critic loss:         543.3604609171549\n",
      "Average reward:      -96.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.036187341601665445\n",
      "Critic loss:         274.3781153361003\n",
      "Average reward:      -94.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03844525579673549\n",
      "Critic loss:         379.14330037434894\n",
      "Average reward:      -94.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03154552658088505\n",
      "Critic loss:         544.7560984293619\n",
      "Average reward:      -95.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03642569652341384\n",
      "Critic loss:         407.79158147176105\n",
      "Average reward:      -94.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03977256860343914\n",
      "Critic loss:         251.13813273111978\n",
      "Average reward:      -90.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03180629244889133\n",
      "Critic loss:         343.4867757161458\n",
      "Average reward:      -93.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03285320363769036\n",
      "Critic loss:         457.5632616678874\n",
      "Average reward:      -94.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035599364045386515\n",
      "Critic loss:         341.95592498779297\n",
      "Average reward:      -96.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037128307570431694\n",
      "Critic loss:         334.69565836588544\n",
      "Average reward:      -92.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03672160087929418\n",
      "Critic loss:         417.36302185058594\n",
      "Average reward:      -94.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03418220503954217\n",
      "Critic loss:         396.49070103963214\n",
      "Average reward:      -92.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037037960602901876\n",
      "Critic loss:         270.6083615620931\n",
      "Average reward:      -90.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03347316711976115\n",
      "Critic loss:         571.9499804178873\n",
      "Average reward:      -95.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03620135990301302\n",
      "Critic loss:         352.3801918029785\n",
      "Average reward:      -92.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038903617668741695\n",
      "Critic loss:         264.1668046315511\n",
      "Average reward:      -91.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03535334776582507\n",
      "Critic loss:         358.9180539449056\n",
      "Average reward:      -94.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03825164297207569\n",
      "Critic loss:         389.14962641398114\n",
      "Average reward:      -95.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03200631487804154\n",
      "Critic loss:         307.861172358195\n",
      "Average reward:      -90.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031131133786402643\n",
      "Critic loss:         528.5322532653809\n",
      "Average reward:      -93.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03755566144051651\n",
      "Critic loss:         356.6356563568115\n",
      "Average reward:      -92.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03827843817998655\n",
      "Critic loss:         296.64976692199707\n",
      "Average reward:      -90.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03875719384329083\n",
      "Critic loss:         361.18023681640625\n",
      "Average reward:      -93.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038639029022306204\n",
      "Critic loss:         401.1537895202637\n",
      "Average reward:      -96.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035487017267466094\n",
      "Critic loss:         420.23609924316406\n",
      "Average reward:      -93.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03020096430191188\n",
      "Critic loss:         440.4156087239583\n",
      "Average reward:      -92.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.042363174026831985\n",
      "Critic loss:         425.9360758463542\n",
      "Average reward:      -95.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028029145595307153\n",
      "Critic loss:         406.8181622823079\n",
      "Average reward:      -91.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041063593118451536\n",
      "Critic loss:         408.24903233846027\n",
      "Average reward:      -91.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03685670833025748\n",
      "Critic loss:         409.6637713114421\n",
      "Average reward:      -94.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038874989423978455\n",
      "Critic loss:         287.02035586039227\n",
      "Average reward:      -89.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03910072719251426\n",
      "Critic loss:         340.61328887939453\n",
      "Average reward:      -88.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034795938146999106\n",
      "Critic loss:         389.3205820719401\n",
      "Average reward:      -92.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030245879703822236\n",
      "Critic loss:         261.0611031850179\n",
      "Average reward:      -88.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03316459003932929\n",
      "Critic loss:         302.5046812693278\n",
      "Average reward:      -89.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03211833457074439\n",
      "Critic loss:         371.40079498291016\n",
      "Average reward:      -90.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03596725977937846\n",
      "Critic loss:         387.45891825358075\n",
      "Average reward:      -92.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03491742763435468\n",
      "Critic loss:         372.52223714192706\n",
      "Average reward:      -91.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03730018223480632\n",
      "Critic loss:         259.4803886413574\n",
      "Average reward:      -87.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03607970798232903\n",
      "Critic loss:         281.41304842631024\n",
      "Average reward:      -87.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032678331015631557\n",
      "Critic loss:         479.1637306213379\n",
      "Average reward:      -93.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03158080090846246\n",
      "Critic loss:         369.08507029215497\n",
      "Average reward:      -89.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03693942196211234\n",
      "Critic loss:         282.203026453654\n",
      "Average reward:      -91.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03157702684256947\n",
      "Critic loss:         468.5279083251953\n",
      "Average reward:      -92.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03300609067567469\n",
      "Critic loss:         331.5480785369873\n",
      "Average reward:      -86.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031369736088284604\n",
      "Critic loss:         358.0029106140137\n",
      "Average reward:      -88.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03420909986986468\n",
      "Critic loss:         318.65675989786786\n",
      "Average reward:      -90.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.033325554696299754\n",
      "Critic loss:         435.0713946024577\n",
      "Average reward:      -90.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03347354813013226\n",
      "Critic loss:         335.9254404703776\n",
      "Average reward:      -90.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035287259883868195\n",
      "Critic loss:         465.795706431071\n",
      "Average reward:      -92.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037045363016659394\n",
      "Critic loss:         452.9924774169922\n",
      "Average reward:      -94.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034031596539231636\n",
      "Critic loss:         528.2494227091471\n",
      "Average reward:      -93.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03807345393579453\n",
      "Critic loss:         251.5267874399821\n",
      "Average reward:      -86.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037558212847216055\n",
      "Critic loss:         288.63719685872394\n",
      "Average reward:      -88.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03755200518450389\n",
      "Critic loss:         266.93030230204266\n",
      "Average reward:      -89.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028062790025918122\n",
      "Critic loss:         552.2892723083496\n",
      "Average reward:      -93.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0378126470798937\n",
      "Critic loss:         385.2513834635417\n",
      "Average reward:      -89.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03581449047487695\n",
      "Critic loss:         443.9806359608968\n",
      "Average reward:      -88.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039546857835375704\n",
      "Critic loss:         424.74516677856445\n",
      "Average reward:      -91.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03971295271306493\n",
      "Critic loss:         260.8617458343506\n",
      "Average reward:      -85.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03875118100161975\n",
      "Critic loss:         337.21549733479816\n",
      "Average reward:      -87.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03912502666935325\n",
      "Critic loss:         262.0843200683594\n",
      "Average reward:      -86.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031961231773796804\n",
      "Critic loss:         352.17710240681964\n",
      "Average reward:      -87.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03523415016631285\n",
      "Critic loss:         261.74365997314453\n",
      "Average reward:      -85.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030530038891204942\n",
      "Critic loss:         383.75586318969727\n",
      "Average reward:      -88.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04260953972698189\n",
      "Critic loss:         265.75110244750977\n",
      "Average reward:      -87.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03823151172643217\n",
      "Critic loss:         304.43147468566895\n",
      "Average reward:      -85.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037073652318213135\n",
      "Critic loss:         296.7213598887126\n",
      "Average reward:      -89.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03593602624217359\n",
      "Critic loss:         328.11126200358075\n",
      "Average reward:      -86.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0348471695324406\n",
      "Critic loss:         419.8860155741374\n",
      "Average reward:      -86.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03723705237886558\n",
      "Critic loss:         300.5573380788167\n",
      "Average reward:      -84.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03778431845421437\n",
      "Critic loss:         273.8562297821045\n",
      "Average reward:      -87.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034170030519211046\n",
      "Critic loss:         290.2669264475505\n",
      "Average reward:      -86.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03887298988411203\n",
      "Critic loss:         274.52347501118976\n",
      "Average reward:      -84.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03735468440087667\n",
      "Critic loss:         328.37182490030926\n",
      "Average reward:      -85.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04174111608881503\n",
      "Critic loss:         318.24220021565753\n",
      "Average reward:      -87.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03994714410509914\n",
      "Critic loss:         277.04556465148926\n",
      "Average reward:      -84.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037789351168612484\n",
      "Critic loss:         317.24534861246747\n",
      "Average reward:      -84.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04143020536381906\n",
      "Critic loss:         170.70951779683432\n",
      "Average reward:      -80.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03579702152152701\n",
      "Critic loss:         499.1108678181966\n",
      "Average reward:      -89.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03259523637825623\n",
      "Critic loss:         323.6031748453776\n",
      "Average reward:      -86.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038119982016117625\n",
      "Critic loss:         395.323050181071\n",
      "Average reward:      -89.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03352964601557081\n",
      "Critic loss:         345.4869575500488\n",
      "Average reward:      -85.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03720180723272885\n",
      "Critic loss:         369.16622670491535\n",
      "Average reward:      -91.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03610312919287632\n",
      "Critic loss:         302.8816286722819\n",
      "Average reward:      -86.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03178682713769376\n",
      "Critic loss:         503.83456166585285\n",
      "Average reward:      -87.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038599817950550154\n",
      "Critic loss:         359.1453145345052\n",
      "Average reward:      -88.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038959509324437626\n",
      "Critic loss:         297.33893330891925\n",
      "Average reward:      -85.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041680740289545305\n",
      "Critic loss:         377.7772699991862\n",
      "Average reward:      -89.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03586672162055038\n",
      "Critic loss:         347.7041308085124\n",
      "Average reward:      -87.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03856921627690705\n",
      "Critic loss:         419.5782407124837\n",
      "Average reward:      -90.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036790113032717876\n",
      "Critic loss:         335.4686864217122\n",
      "Average reward:      -85.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03369053918868303\n",
      "Critic loss:         377.31707127888996\n",
      "Average reward:      -83.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.041063935263082385\n",
      "Critic loss:         281.3529733022054\n",
      "Average reward:      -82.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03640435472577034\n",
      "Critic loss:         279.6740582784017\n",
      "Average reward:      -83.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03868755048218494\n",
      "Critic loss:         200.35679054260254\n",
      "Average reward:      -81.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03442407577919463\n",
      "Critic loss:         315.8892714182536\n",
      "Average reward:      -83.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03452295266712705\n",
      "Critic loss:         335.0393594106038\n",
      "Average reward:      -83.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03609280241653323\n",
      "Critic loss:         282.67951583862305\n",
      "Average reward:      -84.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033409284961332254\n",
      "Critic loss:         320.44124603271484\n",
      "Average reward:      -80.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029135282733477652\n",
      "Critic loss:         451.63236236572266\n",
      "Average reward:      -86.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03954556659058047\n",
      "Critic loss:         294.3010883331299\n",
      "Average reward:      -83.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04101657601616656\n",
      "Critic loss:         257.8891722361247\n",
      "Average reward:      -82.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03223902887354294\n",
      "Critic loss:         375.5564308166504\n",
      "Average reward:      -84.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03520589527518799\n",
      "Critic loss:         332.0322945912679\n",
      "Average reward:      -87.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032569202536251396\n",
      "Critic loss:         524.5646896362305\n",
      "Average reward:      -88.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03722266741290999\n",
      "Critic loss:         433.7699152628581\n",
      "Average reward:      -87.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03631528705591336\n",
      "Critic loss:         269.93602625528973\n",
      "Average reward:      -81.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03426802006045667\n",
      "Critic loss:         357.83788172403973\n",
      "Average reward:      -83.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03471226358184746\n",
      "Critic loss:         258.39868545532227\n",
      "Average reward:      -82.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03334741603218087\n",
      "Critic loss:         410.6686375935872\n",
      "Average reward:      -84.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03817373611188183\n",
      "Critic loss:         327.2337010701497\n",
      "Average reward:      -81.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039009065684998255\n",
      "Critic loss:         271.17451032002765\n",
      "Average reward:      -78.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03876641679865619\n",
      "Critic loss:         269.5526758829753\n",
      "Average reward:      -83.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03719493366224924\n",
      "Critic loss:         279.017884572347\n",
      "Average reward:      -81.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03162481804126097\n",
      "Critic loss:         361.671781539917\n",
      "Average reward:      -80.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03925671009346843\n",
      "Critic loss:         251.14782079060873\n",
      "Average reward:      -78.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03987270259919266\n",
      "Critic loss:         268.13983217875165\n",
      "Average reward:      -78.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04168342047705664\n",
      "Critic loss:         226.26722208658853\n",
      "Average reward:      -76.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03860258836114857\n",
      "Critic loss:         196.1406930287679\n",
      "Average reward:      -77.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037226414249744266\n",
      "Critic loss:         363.7992337544759\n",
      "Average reward:      -84.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037361023908791445\n",
      "Critic loss:         306.08333079020184\n",
      "Average reward:      -83.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03993968172289897\n",
      "Critic loss:         250.3417205810547\n",
      "Average reward:      -81.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03447205052846888\n",
      "Critic loss:         393.0808931986491\n",
      "Average reward:      -82.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03847146992726872\n",
      "Critic loss:         209.28660901387533\n",
      "Average reward:      -76.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034466920488436394\n",
      "Critic loss:         316.23085530598956\n",
      "Average reward:      -83.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03417795894589896\n",
      "Critic loss:         317.03420384724933\n",
      "Average reward:      -80.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03307675869048884\n",
      "Critic loss:         299.52788670857746\n",
      "Average reward:      -84.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03906551906644987\n",
      "Critic loss:         250.54341252644858\n",
      "Average reward:      -78.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037132670728169614\n",
      "Critic loss:         195.00401751200357\n",
      "Average reward:      -76.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03476381624204805\n",
      "Critic loss:         218.47819964090982\n",
      "Average reward:      -78.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03866945713525638\n",
      "Critic loss:         215.75493303934732\n",
      "Average reward:      -76.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0406887773424387\n",
      "Critic loss:         180.44579442342123\n",
      "Average reward:      -76.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03756647464615526\n",
      "Critic loss:         270.95705159505206\n",
      "Average reward:      -80.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036882513687790684\n",
      "Critic loss:         253.4243984222412\n",
      "Average reward:      -76.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04217945354563805\n",
      "Critic loss:         204.75886154174805\n",
      "Average reward:      -76.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03177838744401621\n",
      "Critic loss:         258.7683499654134\n",
      "Average reward:      -76.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0345729942394731\n",
      "Critic loss:         293.4615707397461\n",
      "Average reward:      -80.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03336355726059992\n",
      "Critic loss:         304.53407351175946\n",
      "Average reward:      -78.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03671891655540094\n",
      "Critic loss:         331.9026056925456\n",
      "Average reward:      -78.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.044894929024546094\n",
      "Critic loss:         193.38634808858237\n",
      "Average reward:      -73.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03795919175596888\n",
      "Critic loss:         236.17636426289877\n",
      "Average reward:      -75.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04128031999183198\n",
      "Critic loss:         204.7645632425944\n",
      "Average reward:      -75.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03662431791478108\n",
      "Critic loss:         316.7308540344238\n",
      "Average reward:      -79.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037979500950314105\n",
      "Critic loss:         269.98720359802246\n",
      "Average reward:      -79.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03727647239187112\n",
      "Critic loss:         204.84773127237955\n",
      "Average reward:      -76.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038176583696137335\n",
      "Critic loss:         262.6327667236328\n",
      "Average reward:      -76.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041892148340897016\n",
      "Critic loss:         204.46003532409668\n",
      "Average reward:      -75.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03582000571138148\n",
      "Critic loss:         205.7190087636312\n",
      "Average reward:      -76.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035661842402381204\n",
      "Critic loss:         378.36947377522785\n",
      "Average reward:      -79.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03901963906052212\n",
      "Critic loss:         231.61052131652832\n",
      "Average reward:      -73.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03732736468070167\n",
      "Critic loss:         277.31283887227374\n",
      "Average reward:      -77.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03632063581608236\n",
      "Critic loss:         320.02175458272296\n",
      "Average reward:      -76.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03728307025085087\n",
      "Critic loss:         182.86268170674643\n",
      "Average reward:      -72.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03705176465640155\n",
      "Critic loss:         262.78503545125324\n",
      "Average reward:      -76.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03751689257721106\n",
      "Critic loss:         242.93090947469076\n",
      "Average reward:      -76.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035393783735344186\n",
      "Critic loss:         222.04539934794107\n",
      "Average reward:      -77.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030878135391200583\n",
      "Critic loss:         355.44701766967773\n",
      "Average reward:      -79.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035692054933557905\n",
      "Critic loss:         285.1885509490967\n",
      "Average reward:      -77.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036425164270137124\n",
      "Critic loss:         258.33341153462726\n",
      "Average reward:      -74.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035850346534668155\n",
      "Critic loss:         302.24128850301105\n",
      "Average reward:      -73.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03652529032357658\n",
      "Critic loss:         251.20613543192545\n",
      "Average reward:      -76.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03828286227508215\n",
      "Critic loss:         237.69780604044595\n",
      "Average reward:      -76.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03566544033431759\n",
      "Critic loss:         290.84235127766925\n",
      "Average reward:      -74.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041175159868240975\n",
      "Critic loss:         150.22782389322916\n",
      "Average reward:      -72.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03672398220320853\n",
      "Critic loss:         251.68992233276367\n",
      "Average reward:      -74.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035004711642007656\n",
      "Critic loss:         336.1544380187988\n",
      "Average reward:      -76.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04224706282063077\n",
      "Critic loss:         257.3564281463623\n",
      "Average reward:      -74.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03887387969492314\n",
      "Critic loss:         267.9480546315511\n",
      "Average reward:      -77.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019375859051554773\n",
      "Critic loss:         264.6161988576253\n",
      "Average reward:      -73.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03226510281698817\n",
      "Critic loss:         368.3465054829915\n",
      "Average reward:      -74.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038030192110454664\n",
      "Critic loss:         285.00377082824707\n",
      "Average reward:      -77.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039145244843287706\n",
      "Critic loss:         258.93838183085126\n",
      "Average reward:      -77.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03901935678247052\n",
      "Critic loss:         188.65062459309897\n",
      "Average reward:      -72.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03403531393269077\n",
      "Critic loss:         253.11608759562174\n",
      "Average reward:      -75.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03416957794494616\n",
      "Critic loss:         359.88061332702637\n",
      "Average reward:      -79.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04238294068879137\n",
      "Critic loss:         160.86553510030112\n",
      "Average reward:      -70.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03806990705197677\n",
      "Critic loss:         200.34214973449707\n",
      "Average reward:      -73.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03782766759589625\n",
      "Critic loss:         210.17388725280762\n",
      "Average reward:      -72.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03526476293457866\n",
      "Critic loss:         272.43883260091144\n",
      "Average reward:      -74.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03637619202102845\n",
      "Critic loss:         210.83978907267252\n",
      "Average reward:      -71.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03356546953242893\n",
      "Critic loss:         249.5928840637207\n",
      "Average reward:      -75.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03870093008542123\n",
      "Critic loss:         194.04368209838867\n",
      "Average reward:      -71.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03659195621003164\n",
      "Critic loss:         338.18241119384766\n",
      "Average reward:      -78.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035657295443040006\n",
      "Critic loss:         241.16877555847168\n",
      "Average reward:      -70.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.039581493862594165\n",
      "Critic loss:         211.444065729777\n",
      "Average reward:      -71.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034614934212489366\n",
      "Critic loss:         274.6730257670085\n",
      "Average reward:      -71.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031153001512090366\n",
      "Critic loss:         283.70187123616535\n",
      "Average reward:      -71.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039163163068375674\n",
      "Critic loss:         273.10674476623535\n",
      "Average reward:      -76.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0417060612332231\n",
      "Critic loss:         174.9991372426351\n",
      "Average reward:      -71.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039639550319407135\n",
      "Critic loss:         236.86755434672037\n",
      "Average reward:      -71.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035534305517406516\n",
      "Critic loss:         245.91368420918783\n",
      "Average reward:      -71.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03478565909608733\n",
      "Critic loss:         247.30449930826822\n",
      "Average reward:      -74.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03919229864550289\n",
      "Critic loss:         182.45605023701987\n",
      "Average reward:      -69.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03863885308965109\n",
      "Critic loss:         223.70950317382812\n",
      "Average reward:      -73.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.040792251393819846\n",
      "Critic loss:         224.9395211537679\n",
      "Average reward:      -71.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03837431501597166\n",
      "Critic loss:         241.11101468404135\n",
      "Average reward:      -74.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035677898558788\n",
      "Critic loss:         257.5390148162842\n",
      "Average reward:      -73.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03801538215096419\n",
      "Critic loss:         190.80881309509277\n",
      "Average reward:      -72.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03538417664822191\n",
      "Critic loss:         246.55920473734537\n",
      "Average reward:      -72.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03577014398191144\n",
      "Critic loss:         218.61178970336914\n",
      "Average reward:      -71.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032243800827321444\n",
      "Critic loss:         247.7289161682129\n",
      "Average reward:      -73.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036573636306760214\n",
      "Critic loss:         209.48848025004068\n",
      "Average reward:      -72.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03352178598773511\n",
      "Critic loss:         368.35834376017254\n",
      "Average reward:      -77.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03732857757131569\n",
      "Critic loss:         243.0462760925293\n",
      "Average reward:      -70.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031078134391767282\n",
      "Critic loss:         367.91122182210285\n",
      "Average reward:      -77.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038740149444493\n",
      "Critic loss:         294.24293454488117\n",
      "Average reward:      -74.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038791798249197505\n",
      "Critic loss:         204.88327662150064\n",
      "Average reward:      -69.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03366859824745916\n",
      "Critic loss:         156.49035199483237\n",
      "Average reward:      -71.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03606628697404327\n",
      "Critic loss:         206.18314933776855\n",
      "Average reward:      -70.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03465434482010702\n",
      "Critic loss:         215.34416389465332\n",
      "Average reward:      -72.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027236680616624653\n",
      "Critic loss:         235.40183321634927\n",
      "Average reward:      -74.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03702485483518103\n",
      "Critic loss:         278.16625531514484\n",
      "Average reward:      -71.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035727821251687907\n",
      "Critic loss:         223.49511019388834\n",
      "Average reward:      -70.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041223122854717076\n",
      "Critic loss:         216.93341382344565\n",
      "Average reward:      -71.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04026637761853635\n",
      "Critic loss:         189.05348587036133\n",
      "Average reward:      -70.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.040036215791284725\n",
      "Critic loss:         195.68262481689453\n",
      "Average reward:      -70.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0380264978618167\n",
      "Critic loss:         211.5873260498047\n",
      "Average reward:      -70.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03630408726166934\n",
      "Critic loss:         247.71457608540854\n",
      "Average reward:      -71.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.044351270325326674\n",
      "Critic loss:         161.08355585734049\n",
      "Average reward:      -68.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035164934321073815\n",
      "Critic loss:         291.64246368408203\n",
      "Average reward:      -72.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0377527833431183\n",
      "Critic loss:         200.8762633005778\n",
      "Average reward:      -72.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03658246466269096\n",
      "Critic loss:         194.3754742940267\n",
      "Average reward:      -68.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03955025376732616\n",
      "Critic loss:         195.81622632344565\n",
      "Average reward:      -69.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03754021266771209\n",
      "Critic loss:         195.42444229125977\n",
      "Average reward:      -71.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036920041689882055\n",
      "Critic loss:         182.4237543741862\n",
      "Average reward:      -69.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02889767289161682\n",
      "Critic loss:         392.7303771972656\n",
      "Average reward:      -76.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03998945127629364\n",
      "Critic loss:         179.85629590352377\n",
      "Average reward:      -69.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03557434905087575\n",
      "Critic loss:         223.038605372111\n",
      "Average reward:      -70.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04406681828550063\n",
      "Critic loss:         162.37807909647623\n",
      "Average reward:      -68.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03758868398047829\n",
      "Critic loss:         221.89703114827475\n",
      "Average reward:      -71.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03676032559693946\n",
      "Critic loss:         219.4599412282308\n",
      "Average reward:      -69.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04006576041380564\n",
      "Critic loss:         173.36288770039877\n",
      "Average reward:      -69.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03519153747280749\n",
      "Critic loss:         204.0969581604004\n",
      "Average reward:      -68.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03719747039334228\n",
      "Critic loss:         217.03882535298666\n",
      "Average reward:      -69.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035161503053435204\n",
      "Critic loss:         260.8678773244222\n",
      "Average reward:      -71.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0413985373985876\n",
      "Critic loss:         221.6009953816732\n",
      "Average reward:      -71.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032869555453847475\n",
      "Critic loss:         277.78854179382324\n",
      "Average reward:      -70.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03464146165060811\n",
      "Critic loss:         270.6710548400879\n",
      "Average reward:      -69.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037111853511305526\n",
      "Critic loss:         205.73707834879556\n",
      "Average reward:      -67.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03736121098821362\n",
      "Critic loss:         147.06923611958823\n",
      "Average reward:      -65.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034086785841888435\n",
      "Critic loss:         258.533504486084\n",
      "Average reward:      -71.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04188442872449135\n",
      "Critic loss:         158.33938312530518\n",
      "Average reward:      -65.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036177591250937745\n",
      "Critic loss:         203.8593953450521\n",
      "Average reward:      -69.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037892933372252934\n",
      "Critic loss:         166.45951970418295\n",
      "Average reward:      -66.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04096567813151827\n",
      "Critic loss:         187.6520938873291\n",
      "Average reward:      -71.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03553286330619206\n",
      "Critic loss:         146.64778741200766\n",
      "Average reward:      -63.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04049316805321723\n",
      "Critic loss:         182.55615615844727\n",
      "Average reward:      -67.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04076177309616469\n",
      "Critic loss:         212.1763235727946\n",
      "Average reward:      -68.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03169585983171904\n",
      "Critic loss:         297.6018937428792\n",
      "Average reward:      -70.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03885182488011196\n",
      "Critic loss:         325.26952234903973\n",
      "Average reward:      -72.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04429618287637519\n",
      "Critic loss:         147.09957599639893\n",
      "Average reward:      -67.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03703814531521251\n",
      "Critic loss:         195.03830655415854\n",
      "Average reward:      -66.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02815473419226085\n",
      "Critic loss:         280.20246569315594\n",
      "Average reward:      -71.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037321431789375005\n",
      "Critic loss:         206.19790903727213\n",
      "Average reward:      -70.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03850031567950888\n",
      "Critic loss:         188.02632840474448\n",
      "Average reward:      -66.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03795457935484592\n",
      "Critic loss:         279.6608308156331\n",
      "Average reward:      -71.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03685829388753822\n",
      "Critic loss:         258.80297724405926\n",
      "Average reward:      -69.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03652322990819812\n",
      "Critic loss:         205.19239044189453\n",
      "Average reward:      -68.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04025755921490296\n",
      "Critic loss:         194.97765096028647\n",
      "Average reward:      -68.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0394069658529285\n",
      "Critic loss:         183.76145108540854\n",
      "Average reward:      -66.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039404307171935216\n",
      "Critic loss:         158.7562224070231\n",
      "Average reward:      -67.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03614391832767675\n",
      "Critic loss:         245.74025917053223\n",
      "Average reward:      -69.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03550130032817833\n",
      "Critic loss:         214.7180608113607\n",
      "Average reward:      -68.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037159012902217604\n",
      "Critic loss:         144.4830535252889\n",
      "Average reward:      -63.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03190329575833554\n",
      "Critic loss:         240.5927219390869\n",
      "Average reward:      -69.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.040718195106213294\n",
      "Critic loss:         187.53491020202637\n",
      "Average reward:      -69.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.042092631900838264\n",
      "Critic loss:         178.59366989135742\n",
      "Average reward:      -70.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03863368386131091\n",
      "Critic loss:         214.81784184773764\n",
      "Average reward:      -70.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03567901822195078\n",
      "Critic loss:         217.83126513163248\n",
      "Average reward:      -68.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029777815759492416\n",
      "Critic loss:         260.47546195983887\n",
      "Average reward:      -68.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038163801499952875\n",
      "Critic loss:         162.07866350809732\n",
      "Average reward:      -68.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04021069155229876\n",
      "Critic loss:         158.46456082661948\n",
      "Average reward:      -66.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03459987530853444\n",
      "Critic loss:         163.80647659301758\n",
      "Average reward:      -64.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03077702706408066\n",
      "Critic loss:         373.43016115824383\n",
      "Average reward:      -71.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03770709103749444\n",
      "Critic loss:         208.2492275238037\n",
      "Average reward:      -68.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029745334080265213\n",
      "Critic loss:         264.7691224416097\n",
      "Average reward:      -67.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03880867106878819\n",
      "Critic loss:         206.95395469665527\n",
      "Average reward:      -67.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03486233144455279\n",
      "Critic loss:         180.10246213277182\n",
      "Average reward:      -65.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03087689708263497\n",
      "Critic loss:         281.9793872833252\n",
      "Average reward:      -66.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036184074983642255\n",
      "Critic loss:         219.21476682027182\n",
      "Average reward:      -67.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028863802096263196\n",
      "Critic loss:         271.489216486613\n",
      "Average reward:      -68.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03834395227022469\n",
      "Critic loss:         192.26490592956543\n",
      "Average reward:      -67.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03838471561903134\n",
      "Critic loss:         170.47906303405762\n",
      "Average reward:      -68.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0259258252329649\n",
      "Critic loss:         193.84941037495932\n",
      "Average reward:      -67.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03268690614883477\n",
      "Critic loss:         229.25995318094888\n",
      "Average reward:      -67.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03658962802728638\n",
      "Critic loss:         182.18266105651855\n",
      "Average reward:      -67.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031046639201425325\n",
      "Critic loss:         218.99941190083823\n",
      "Average reward:      -67.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03223586909007281\n",
      "Critic loss:         241.77778752644858\n",
      "Average reward:      -69.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03272092907839882\n",
      "Critic loss:         246.62040201822916\n",
      "Average reward:      -67.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03577372108217484\n",
      "Critic loss:         247.37519963582358\n",
      "Average reward:      -69.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037634425631646685\n",
      "Critic loss:         152.98243840535483\n",
      "Average reward:      -65.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035315766335770604\n",
      "Critic loss:         208.0021947224935\n",
      "Average reward:      -67.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03683222631419388\n",
      "Critic loss:         201.4604288736979\n",
      "Average reward:      -67.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029566418651180964\n",
      "Critic loss:         373.0436312357585\n",
      "Average reward:      -71.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033120906203597165\n",
      "Critic loss:         261.5348593393962\n",
      "Average reward:      -70.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03651340232075503\n",
      "Critic loss:         226.766871770223\n",
      "Average reward:      -70.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03808264693361707\n",
      "Critic loss:         224.79488118489584\n",
      "Average reward:      -68.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03676950694837918\n",
      "Critic loss:         219.35839907328287\n",
      "Average reward:      -68.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03550249639859734\n",
      "Critic loss:         200.29728062947592\n",
      "Average reward:      -66.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036456455745186155\n",
      "Critic loss:         253.0172036488851\n",
      "Average reward:      -67.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03800335941681018\n",
      "Critic loss:         230.6506493886312\n",
      "Average reward:      -70.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0389526504004607\n",
      "Critic loss:         193.4283364613851\n",
      "Average reward:      -67.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03692499998336037\n",
      "Critic loss:         260.9953867594401\n",
      "Average reward:      -70.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038217699172795015\n",
      "Critic loss:         201.17984580993652\n",
      "Average reward:      -68.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03839670302598582\n",
      "Critic loss:         170.45456631978354\n",
      "Average reward:      -66.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034617804166676557\n",
      "Critic loss:         190.56507873535156\n",
      "Average reward:      -67.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0355780222453177\n",
      "Critic loss:         235.08013089497885\n",
      "Average reward:      -69.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037399933654038854\n",
      "Critic loss:         279.7691453297933\n",
      "Average reward:      -71.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03932845575036481\n",
      "Critic loss:         212.33636792500815\n",
      "Average reward:      -69.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03313588607610048\n",
      "Critic loss:         173.02591133117676\n",
      "Average reward:      -66.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03316571917578889\n",
      "Critic loss:         410.3125419616699\n",
      "Average reward:      -75.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03924629152364408\n",
      "Critic loss:         180.25112342834473\n",
      "Average reward:      -68.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036102640675380826\n",
      "Critic loss:         217.65805943806967\n",
      "Average reward:      -68.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03444325434975326\n",
      "Critic loss:         244.81947898864746\n",
      "Average reward:      -67.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0406001218483046\n",
      "Critic loss:         237.54937616984049\n",
      "Average reward:      -70.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037904818744512646\n",
      "Critic loss:         243.09472211201987\n",
      "Average reward:      -68.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03793815319174124\n",
      "Critic loss:         228.78981399536133\n",
      "Average reward:      -68.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030401589736963313\n",
      "Critic loss:         378.6786066691081\n",
      "Average reward:      -74.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03591325370750079\n",
      "Critic loss:         199.99156061808267\n",
      "Average reward:      -66.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02920466984990829\n",
      "Critic loss:         411.44905217488605\n",
      "Average reward:      -72.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.04021362584338325\n",
      "Critic loss:         163.58661905924478\n",
      "Average reward:      -66.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03473384047053211\n",
      "Critic loss:         169.01681772867838\n",
      "Average reward:      -64.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.037325033937425665\n",
      "Critic loss:         231.45500500996908\n",
      "Average reward:      -68.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037222792161628604\n",
      "Critic loss:         172.08291625976562\n",
      "Average reward:      -64.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03979151737560945\n",
      "Critic loss:         160.50689824422201\n",
      "Average reward:      -65.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034599447797518224\n",
      "Critic loss:         201.3923823038737\n",
      "Average reward:      -65.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03673631406854838\n",
      "Critic loss:         211.67386118570963\n",
      "Average reward:      -69.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034719368845496014\n",
      "Critic loss:         216.84840202331543\n",
      "Average reward:      -66.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03393675853537085\n",
      "Critic loss:         178.61255582173666\n",
      "Average reward:      -65.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027523940419390176\n",
      "Critic loss:         274.55097007751465\n",
      "Average reward:      -68.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03925520965761583\n",
      "Critic loss:         141.1301237742106\n",
      "Average reward:      -64.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03963279251668913\n",
      "Critic loss:         191.96582412719727\n",
      "Average reward:      -66.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038285527708164103\n",
      "Critic loss:         218.22618548075357\n",
      "Average reward:      -67.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029275359818711877\n",
      "Critic loss:         223.3744239807129\n",
      "Average reward:      -66.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03872417468422403\n",
      "Critic loss:         279.3096466064453\n",
      "Average reward:      -69.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037808963376846805\n",
      "Critic loss:         216.06468963623047\n",
      "Average reward:      -69.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034951159226087235\n",
      "Critic loss:         210.53177197774252\n",
      "Average reward:      -66.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03417093551252037\n",
      "Critic loss:         254.96223513285318\n",
      "Average reward:      -68.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029753658454865217\n",
      "Critic loss:         267.86775398254395\n",
      "Average reward:      -66.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039717236902409546\n",
      "Critic loss:         181.25927829742432\n",
      "Average reward:      -68.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0383528019519872\n",
      "Critic loss:         222.12853304545084\n",
      "Average reward:      -70.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035778385567634054\n",
      "Critic loss:         199.28513145446777\n",
      "Average reward:      -64.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03599708244049301\n",
      "Critic loss:         267.9377867380778\n",
      "Average reward:      -69.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031220640914398246\n",
      "Critic loss:         267.0824839274089\n",
      "Average reward:      -66.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034231091694285475\n",
      "Critic loss:         224.6087506612142\n",
      "Average reward:      -65.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036898626383238785\n",
      "Critic loss:         292.700231552124\n",
      "Average reward:      -71.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.041731795247566573\n",
      "Critic loss:         225.653657913208\n",
      "Average reward:      -68.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0324438483803533\n",
      "Critic loss:         163.84576288859049\n",
      "Average reward:      -63.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.039416807073090844\n",
      "Critic loss:         187.43596013387045\n",
      "Average reward:      -66.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0368300292660327\n",
      "Critic loss:         170.4459603627523\n",
      "Average reward:      -64.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035463003490197785\n",
      "Critic loss:         189.34193547566733\n",
      "Average reward:      -66.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03487669764823901\n",
      "Critic loss:         143.2772954305013\n",
      "Average reward:      -63.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032241168514398545\n",
      "Critic loss:         231.06268501281738\n",
      "Average reward:      -65.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03460279129406748\n",
      "Critic loss:         157.5864102045695\n",
      "Average reward:      -64.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03777039209914316\n",
      "Critic loss:         202.9626897176107\n",
      "Average reward:      -64.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030857757160750527\n",
      "Critic loss:         239.9255453745524\n",
      "Average reward:      -67.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036057682598766405\n",
      "Critic loss:         197.51784070332846\n",
      "Average reward:      -68.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03502092914034923\n",
      "Critic loss:         220.91988627115884\n",
      "Average reward:      -67.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03360951814102009\n",
      "Critic loss:         170.52008183797201\n",
      "Average reward:      -62.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03476703532699806\n",
      "Critic loss:         166.46026929219565\n",
      "Average reward:      -65.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03440373676130548\n",
      "Critic loss:         157.99585978190103\n",
      "Average reward:      -65.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03606166007618109\n",
      "Critic loss:         214.28549830118814\n",
      "Average reward:      -67.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03826416452648118\n",
      "Critic loss:         153.6685094833374\n",
      "Average reward:      -63.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03235007234616205\n",
      "Critic loss:         220.97415351867676\n",
      "Average reward:      -67.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032486499597628914\n",
      "Critic loss:         200.33642069498697\n",
      "Average reward:      -66.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030807578635479633\n",
      "Critic loss:         264.265817006429\n",
      "Average reward:      -67.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033472799515341954\n",
      "Critic loss:         188.3471883138021\n",
      "Average reward:      -65.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034689294814597815\n",
      "Critic loss:         164.5122766494751\n",
      "Average reward:      -63.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03247739097181087\n",
      "Critic loss:         195.9051856994629\n",
      "Average reward:      -67.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03328906727862583\n",
      "Critic loss:         205.13655153910318\n",
      "Average reward:      -63.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038333873031660914\n",
      "Critic loss:         196.38227907816568\n",
      "Average reward:      -65.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03227572570782892\n",
      "Critic loss:         234.91594441731772\n",
      "Average reward:      -65.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027135146966126438\n",
      "Critic loss:         170.8836758931478\n",
      "Average reward:      -62.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03523358427628409\n",
      "Critic loss:         136.01910622914633\n",
      "Average reward:      -63.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03423903896085297\n",
      "Critic loss:         130.7776492436727\n",
      "Average reward:      -60.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033064294897485524\n",
      "Critic loss:         174.42549324035645\n",
      "Average reward:      -63.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03873780383340394\n",
      "Critic loss:         146.65852038065592\n",
      "Average reward:      -63.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033359518041834235\n",
      "Critic loss:         152.7766170501709\n",
      "Average reward:      -62.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034281438177761935\n",
      "Critic loss:         158.4565757115682\n",
      "Average reward:      -63.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0339830193988746\n",
      "Critic loss:         158.21163654327393\n",
      "Average reward:      -64.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035551891196519136\n",
      "Critic loss:         164.89981492360434\n",
      "Average reward:      -62.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037743728064621486\n",
      "Critic loss:         157.97989718119302\n",
      "Average reward:      -61.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032751681874894224\n",
      "Critic loss:         181.3404000600179\n",
      "Average reward:      -63.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03380704026979705\n",
      "Critic loss:         177.4236806233724\n",
      "Average reward:      -62.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03274731206086775\n",
      "Critic loss:         188.31871859232584\n",
      "Average reward:      -65.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034018748740588\n",
      "Critic loss:         173.28676414489746\n",
      "Average reward:      -63.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03606558054161724\n",
      "Critic loss:         159.88421471913657\n",
      "Average reward:      -63.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024355382202581193\n",
      "Critic loss:         141.02444807688394\n",
      "Average reward:      -60.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03595610855942747\n",
      "Critic loss:         133.04334163665771\n",
      "Average reward:      -61.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030487218047104154\n",
      "Critic loss:         257.6637217203776\n",
      "Average reward:      -65.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036950118286767974\n",
      "Critic loss:         119.23552513122559\n",
      "Average reward:      -59.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029359513862194337\n",
      "Critic loss:         387.7831516265869\n",
      "Average reward:      -67.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033595161672565155\n",
      "Critic loss:         173.39545313517252\n",
      "Average reward:      -63.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037550251659316324\n",
      "Critic loss:         169.96138445536295\n",
      "Average reward:      -65.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033191002071058996\n",
      "Critic loss:         209.89753659566244\n",
      "Average reward:      -65.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030785489652771503\n",
      "Critic loss:         259.13111368815106\n",
      "Average reward:      -67.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03122121178572949\n",
      "Critic loss:         217.3872979482015\n",
      "Average reward:      -66.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03421857331765447\n",
      "Critic loss:         224.58782641092935\n",
      "Average reward:      -65.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029880591231631115\n",
      "Critic loss:         171.9793186187744\n",
      "Average reward:      -61.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03520112298429012\n",
      "Critic loss:         173.50613657633463\n",
      "Average reward:      -64.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034900843689683825\n",
      "Critic loss:         175.36440467834473\n",
      "Average reward:      -64.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0331376348961688\n",
      "Critic loss:         203.50922012329102\n",
      "Average reward:      -66.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03403547778725624\n",
      "Critic loss:         206.61155064900717\n",
      "Average reward:      -65.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033260598099635295\n",
      "Critic loss:         171.61795361836752\n",
      "Average reward:      -62.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03863125098481154\n",
      "Critic loss:         134.24690310160318\n",
      "Average reward:      -62.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031289299561952554\n",
      "Critic loss:         200.37856801350912\n",
      "Average reward:      -64.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03622700124590968\n",
      "Critic loss:         179.76863161722818\n",
      "Average reward:      -62.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.037586878500102706\n",
      "Critic loss:         168.60208384195963\n",
      "Average reward:      -61.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03506070273579098\n",
      "Critic loss:         208.68394470214844\n",
      "Average reward:      -65.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031162677371564012\n",
      "Critic loss:         212.21362241109213\n",
      "Average reward:      -63.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03301244371490005\n",
      "Critic loss:         201.31170908610025\n",
      "Average reward:      -62.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.013167474210301103\n",
      "Critic loss:         199.80430030822754\n",
      "Average reward:      -64.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031233986441899713\n",
      "Critic loss:         208.55881118774414\n",
      "Average reward:      -64.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.035009906239186726\n",
      "Critic loss:         223.34186808268228\n",
      "Average reward:      -67.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03224326700243788\n",
      "Critic loss:         222.6424102783203\n",
      "Average reward:      -68.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03718292593354514\n",
      "Critic loss:         190.9321263631185\n",
      "Average reward:      -64.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03115704024336689\n",
      "Critic loss:         204.80408096313477\n",
      "Average reward:      -66.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03149124541717659\n",
      "Critic loss:         265.7462450663249\n",
      "Average reward:      -67.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03290928993374109\n",
      "Critic loss:         201.90404001871744\n",
      "Average reward:      -63.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03409623856471929\n",
      "Critic loss:         263.371129989624\n",
      "Average reward:      -66.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03143271917360835\n",
      "Critic loss:         207.31060473124185\n",
      "Average reward:      -65.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026243750015661742\n",
      "Critic loss:         163.75943501790366\n",
      "Average reward:      -64.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03030541828290249\n",
      "Critic loss:         171.79521115620932\n",
      "Average reward:      -63.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033074135479788914\n",
      "Critic loss:         166.51202233632407\n",
      "Average reward:      -64.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036840517908179514\n",
      "Critic loss:         209.4506607055664\n",
      "Average reward:      -66.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03301889585175862\n",
      "Critic loss:         211.26042048136392\n",
      "Average reward:      -66.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03193053634216388\n",
      "Critic loss:         168.27661005655924\n",
      "Average reward:      -62.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03290504327742383\n",
      "Critic loss:         190.17881774902344\n",
      "Average reward:      -63.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03486657509347424\n",
      "Critic loss:         218.70470746358237\n",
      "Average reward:      -67.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032985048407378294\n",
      "Critic loss:         206.18295415242514\n",
      "Average reward:      -64.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03427216550335288\n",
      "Critic loss:         235.48342005411783\n",
      "Average reward:      -66.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03399623721876802\n",
      "Critic loss:         233.8232282002767\n",
      "Average reward:      -64.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03288451829818465\n",
      "Critic loss:         239.42948786417642\n",
      "Average reward:      -64.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029107676101072382\n",
      "Critic loss:         151.2816832860311\n",
      "Average reward:      -58.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031536720460280776\n",
      "Critic loss:         175.3270092010498\n",
      "Average reward:      -62.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03128198859243033\n",
      "Critic loss:         223.55504989624023\n",
      "Average reward:      -63.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031072325858986005\n",
      "Critic loss:         181.99158414204916\n",
      "Average reward:      -62.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03294600007332823\n",
      "Critic loss:         129.2502759297689\n",
      "Average reward:      -59.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030932607284739788\n",
      "Critic loss:         160.761248588562\n",
      "Average reward:      -60.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03204567238875219\n",
      "Critic loss:         228.3754679361979\n",
      "Average reward:      -65.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03255055292053536\n",
      "Critic loss:         232.29476992289224\n",
      "Average reward:      -66.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029109498563533027\n",
      "Critic loss:         181.46524492899576\n",
      "Average reward:      -62.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03197567067885151\n",
      "Critic loss:         158.93524837493896\n",
      "Average reward:      -62.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033424264955101535\n",
      "Critic loss:         214.6747194925944\n",
      "Average reward:      -63.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.038776478642830625\n",
      "Critic loss:         134.8989381790161\n",
      "Average reward:      -62.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022820176537303876\n",
      "Critic loss:         155.62418715159097\n",
      "Average reward:      -61.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03314207984658424\n",
      "Critic loss:         96.09555594126384\n",
      "Average reward:      -58.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019661100639496\n",
      "Critic loss:         200.35328102111816\n",
      "Average reward:      -64.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03450639992782575\n",
      "Critic loss:         142.58030891418457\n",
      "Average reward:      -61.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032859562208917246\n",
      "Critic loss:         116.26188373565674\n",
      "Average reward:      -60.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033940464665647596\n",
      "Critic loss:         158.3858642578125\n",
      "Average reward:      -61.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03163768173544668\n",
      "Critic loss:         130.87928581237793\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034553847702530525\n",
      "Critic loss:         123.6961030960083\n",
      "Average reward:      -61.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03334972316709658\n",
      "Critic loss:         155.01994641621908\n",
      "Average reward:      -61.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030064017201463383\n",
      "Critic loss:         165.20512453715006\n",
      "Average reward:      -63.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.018098775889181223\n",
      "Critic loss:         179.452667872111\n",
      "Average reward:      -64.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032341608874655016\n",
      "Critic loss:         196.33503214518228\n",
      "Average reward:      -65.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.033008634360157885\n",
      "Critic loss:         200.44155248006186\n",
      "Average reward:      -64.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03275850420808032\n",
      "Critic loss:         190.2533327738444\n",
      "Average reward:      -64.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02671507695534577\n",
      "Critic loss:         198.6648966471354\n",
      "Average reward:      -65.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03105074169191842\n",
      "Critic loss:         204.28841018676758\n",
      "Average reward:      -65.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03339936046177172\n",
      "Critic loss:         173.30588150024414\n",
      "Average reward:      -64.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03531735713719778\n",
      "Critic loss:         153.79479058583578\n",
      "Average reward:      -62.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02830813832891484\n",
      "Critic loss:         235.56500434875488\n",
      "Average reward:      -63.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03347855410902412\n",
      "Critic loss:         153.88697973887125\n",
      "Average reward:      -61.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03316743188770488\n",
      "Critic loss:         220.93932342529297\n",
      "Average reward:      -63.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03525357565861972\n",
      "Critic loss:         111.42031160990398\n",
      "Average reward:      -59.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02674708600776891\n",
      "Critic loss:         259.3583501180013\n",
      "Average reward:      -62.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028122417754881706\n",
      "Critic loss:         211.86932818094888\n",
      "Average reward:      -62.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028761858983974282\n",
      "Critic loss:         202.12826665242514\n",
      "Average reward:      -62.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03370583888317924\n",
      "Critic loss:         173.03894170125326\n",
      "Average reward:      -61.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028071126706587773\n",
      "Critic loss:         167.61558278401694\n",
      "Average reward:      -61.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030248197232140228\n",
      "Critic loss:         125.38805484771729\n",
      "Average reward:      -60.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02829082357735994\n",
      "Critic loss:         167.54034932454428\n",
      "Average reward:      -61.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03225868724985048\n",
      "Critic loss:         123.12524700164795\n",
      "Average reward:      -59.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029468107997672632\n",
      "Critic loss:         125.5861005783081\n",
      "Average reward:      -60.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.034352891865031175\n",
      "Critic loss:         146.10523509979248\n",
      "Average reward:      -62.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030648394218587782\n",
      "Critic loss:         127.31575934092204\n",
      "Average reward:      -59.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029899415734689683\n",
      "Critic loss:         192.15278244018555\n",
      "Average reward:      -62.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03521650810337936\n",
      "Critic loss:         140.55637486775717\n",
      "Average reward:      -62.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03479381046296718\n",
      "Critic loss:         134.45552349090576\n",
      "Average reward:      -60.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031067631954404835\n",
      "Critic loss:         183.86011950174967\n",
      "Average reward:      -64.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03307059429547129\n",
      "Critic loss:         167.2629477183024\n",
      "Average reward:      -61.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03143920991927492\n",
      "Critic loss:         138.66977500915527\n",
      "Average reward:      -60.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03043555854431664\n",
      "Critic loss:         164.6310157775879\n",
      "Average reward:      -62.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03836751865552893\n",
      "Critic loss:         123.35474745432536\n",
      "Average reward:      -61.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029916296179483954\n",
      "Critic loss:         184.3844839731852\n",
      "Average reward:      -61.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03102534931046345\n",
      "Critic loss:         147.5943743387858\n",
      "Average reward:      -61.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02966679061258522\n",
      "Critic loss:         234.19110171000162\n",
      "Average reward:      -64.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03236473144594735\n",
      "Critic loss:         185.78513526916504\n",
      "Average reward:      -62.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02988498075865209\n",
      "Critic loss:         235.83516693115234\n",
      "Average reward:      -64.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0304162701019474\n",
      "Critic loss:         193.63146464029947\n",
      "Average reward:      -62.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03036199722555466\n",
      "Critic loss:         145.71175702412924\n",
      "Average reward:      -59.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028866181521152612\n",
      "Critic loss:         124.54229831695557\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02245532989036292\n",
      "Critic loss:         212.67693328857422\n",
      "Average reward:      -61.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03171442521852441\n",
      "Critic loss:         117.476944287618\n",
      "Average reward:      -58.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02908405553898774\n",
      "Critic loss:         179.38162803649902\n",
      "Average reward:      -60.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02557120332494378\n",
      "Critic loss:         173.627171198527\n",
      "Average reward:      -60.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03275075451400274\n",
      "Critic loss:         130.2148208618164\n",
      "Average reward:      -59.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027851330911895882\n",
      "Critic loss:         163.94733746846518\n",
      "Average reward:      -60.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032316146835607164\n",
      "Critic loss:         127.39209938049316\n",
      "Average reward:      -59.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03038181654604462\n",
      "Critic loss:         159.87314065297446\n",
      "Average reward:      -61.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02731325403631975\n",
      "Critic loss:         156.69245688120523\n",
      "Average reward:      -60.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030440292636437032\n",
      "Critic loss:         186.7742067972819\n",
      "Average reward:      -62.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019815267296507955\n",
      "Critic loss:         148.06232261657715\n",
      "Average reward:      -61.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028954560662289925\n",
      "Critic loss:         150.2564516067505\n",
      "Average reward:      -60.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.03245699058364456\n",
      "Critic loss:         172.38913790384927\n",
      "Average reward:      -64.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03424595150863752\n",
      "Critic loss:         227.76880009969076\n",
      "Average reward:      -65.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028296188759365275\n",
      "Critic loss:         172.57370249430338\n",
      "Average reward:      -59.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029276003032767523\n",
      "Critic loss:         187.15024757385254\n",
      "Average reward:      -62.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028873670458172757\n",
      "Critic loss:         178.3780549367269\n",
      "Average reward:      -60.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.036417248459959715\n",
      "Critic loss:         127.64661916097005\n",
      "Average reward:      -60.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029623473043708753\n",
      "Critic loss:         187.16702874501547\n",
      "Average reward:      -60.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026929132795582216\n",
      "Critic loss:         154.41530736287436\n",
      "Average reward:      -60.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030897497296488535\n",
      "Critic loss:         176.48851267496744\n",
      "Average reward:      -63.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03086602219264023\n",
      "Critic loss:         102.92639605204265\n",
      "Average reward:      -57.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027424971712510644\n",
      "Critic loss:         170.64943313598633\n",
      "Average reward:      -60.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024324932538244564\n",
      "Critic loss:         156.78237056732178\n",
      "Average reward:      -59.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028435425638842087\n",
      "Critic loss:         97.50175857543945\n",
      "Average reward:      -57.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03625122380132476\n",
      "Critic loss:         96.8519795735677\n",
      "Average reward:      -58.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027676506533074036\n",
      "Critic loss:         161.52835369110107\n",
      "Average reward:      -60.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027720073199210066\n",
      "Critic loss:         245.12640444437662\n",
      "Average reward:      -63.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0294419505711024\n",
      "Critic loss:         168.6511443456014\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02873714462960682\n",
      "Critic loss:         180.13260873158774\n",
      "Average reward:      -60.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027849636661509674\n",
      "Critic loss:         154.2191883722941\n",
      "Average reward:      -59.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02737130137393251\n",
      "Critic loss:         203.18858337402344\n",
      "Average reward:      -61.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022036609368418187\n",
      "Critic loss:         182.26395257314047\n",
      "Average reward:      -61.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028495599850430153\n",
      "Critic loss:         147.0270611445109\n",
      "Average reward:      -59.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026509170459272962\n",
      "Critic loss:         80.11527999242146\n",
      "Average reward:      -56.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032702948379058704\n",
      "Critic loss:         88.63947264353435\n",
      "Average reward:      -56.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030414579339170206\n",
      "Critic loss:         181.87186527252197\n",
      "Average reward:      -62.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030732503665300708\n",
      "Critic loss:         142.70649751027426\n",
      "Average reward:      -59.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028882180161114473\n",
      "Critic loss:         140.93052991231283\n",
      "Average reward:      -59.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029301465139724314\n",
      "Critic loss:         98.07793935139973\n",
      "Average reward:      -56.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.032213670213726196\n",
      "Critic loss:         120.20465056101482\n",
      "Average reward:      -58.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026455141738097154\n",
      "Critic loss:         200.44294865926108\n",
      "Average reward:      -60.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027244065146078356\n",
      "Critic loss:         165.84112866719565\n",
      "Average reward:      -59.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030116759250328567\n",
      "Critic loss:         178.57305463155112\n",
      "Average reward:      -62.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030342373060799826\n",
      "Critic loss:         151.15881220499674\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028402199740715634\n",
      "Critic loss:         133.66512966156006\n",
      "Average reward:      -59.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024206873941390466\n",
      "Critic loss:         230.1146183013916\n",
      "Average reward:      -62.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026537099271081388\n",
      "Critic loss:         150.01942666371664\n",
      "Average reward:      -58.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024440454901196063\n",
      "Critic loss:         123.27313486735027\n",
      "Average reward:      -59.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022874044834073477\n",
      "Critic loss:         287.5500742594401\n",
      "Average reward:      -61.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027748022281533242\n",
      "Critic loss:         137.3181006113688\n",
      "Average reward:      -56.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029563747424011428\n",
      "Critic loss:         139.45620663960776\n",
      "Average reward:      -58.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0255641945792983\n",
      "Critic loss:         114.01222546895345\n",
      "Average reward:      -57.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024974411209313985\n",
      "Critic loss:         125.96916166941325\n",
      "Average reward:      -58.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022867719574909035\n",
      "Critic loss:         116.07053438822429\n",
      "Average reward:      -59.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028931770459166728\n",
      "Critic loss:         130.0965143839518\n",
      "Average reward:      -59.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023260786906272795\n",
      "Critic loss:         153.71481450398764\n",
      "Average reward:      -58.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029299489200639073\n",
      "Critic loss:         118.14849758148193\n",
      "Average reward:      -60.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.027930323830029618\n",
      "Critic loss:         125.06231021881104\n",
      "Average reward:      -59.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02721153291774196\n",
      "Critic loss:         106.63762124379475\n",
      "Average reward:      -58.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03060299302645338\n",
      "Critic loss:         138.54537932078043\n",
      "Average reward:      -59.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023493777681627154\n",
      "Critic loss:         130.96991952260336\n",
      "Average reward:      -59.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02428542453950892\n",
      "Critic loss:         205.17308870951334\n",
      "Average reward:      -59.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03179090771057721\n",
      "Critic loss:         107.39416376749675\n",
      "Average reward:      -58.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029098119450888287\n",
      "Critic loss:         129.2947161992391\n",
      "Average reward:      -59.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027664750698022544\n",
      "Critic loss:         178.00806713104248\n",
      "Average reward:      -60.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021347509586727636\n",
      "Critic loss:         126.12896664937337\n",
      "Average reward:      -57.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03135712662090858\n",
      "Critic loss:         79.09994697570801\n",
      "Average reward:      -57.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02444522551377304\n",
      "Critic loss:         138.37406476338705\n",
      "Average reward:      -57.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02838035172317177\n",
      "Critic loss:         141.54077625274658\n",
      "Average reward:      -58.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020909307679782312\n",
      "Critic loss:         166.52110322316489\n",
      "Average reward:      -58.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026001707864149164\n",
      "Critic loss:         137.06886672973633\n",
      "Average reward:      -58.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026444452892368037\n",
      "Critic loss:         95.88480949401855\n",
      "Average reward:      -56.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025021493745346863\n",
      "Critic loss:         163.7950096130371\n",
      "Average reward:      -58.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02623512710367019\n",
      "Critic loss:         130.14003721872965\n",
      "Average reward:      -57.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02413177028544548\n",
      "Critic loss:         173.6095339457194\n",
      "Average reward:      -60.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027066946456519265\n",
      "Critic loss:         139.18891779581705\n",
      "Average reward:      -58.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022140417010329354\n",
      "Critic loss:         125.33712959289551\n",
      "Average reward:      -56.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02036494541486415\n",
      "Critic loss:         115.5947847366333\n",
      "Average reward:      -58.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02804817454064808\n",
      "Critic loss:         212.85201263427734\n",
      "Average reward:      -62.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.031075470459957916\n",
      "Critic loss:         152.4825118382772\n",
      "Average reward:      -60.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026157711810204393\n",
      "Critic loss:         124.27983792622884\n",
      "Average reward:      -57.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022842116188257933\n",
      "Critic loss:         175.0045305887858\n",
      "Average reward:      -59.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028108357243278686\n",
      "Critic loss:         115.05997435251872\n",
      "Average reward:      -59.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023382653744192794\n",
      "Critic loss:         136.97618039449057\n",
      "Average reward:      -59.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02864446392050013\n",
      "Critic loss:         125.78739897410075\n",
      "Average reward:      -58.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027084322568650048\n",
      "Critic loss:         155.35236263275146\n",
      "Average reward:      -59.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02562759703626701\n",
      "Critic loss:         167.95602067311606\n",
      "Average reward:      -59.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027753676753491163\n",
      "Critic loss:         141.28626346588135\n",
      "Average reward:      -59.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026130902791919652\n",
      "Critic loss:         120.93558692932129\n",
      "Average reward:      -57.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023330578396174435\n",
      "Critic loss:         132.02693049112955\n",
      "Average reward:      -57.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01587991205936608\n",
      "Critic loss:         236.11203034718832\n",
      "Average reward:      -58.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01984279667036996\n",
      "Critic loss:         189.08510526021323\n",
      "Average reward:      -61.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02730641351081431\n",
      "Critic loss:         190.47320874532065\n",
      "Average reward:      -58.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01872482793017601\n",
      "Critic loss:         130.58346271514893\n",
      "Average reward:      -56.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02459266393634607\n",
      "Critic loss:         163.76762866973877\n",
      "Average reward:      -59.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024099024206710357\n",
      "Critic loss:         227.5718091328939\n",
      "Average reward:      -61.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0301981768522334\n",
      "Critic loss:         160.46891434987387\n",
      "Average reward:      -57.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0193996219654764\n",
      "Critic loss:         217.05404408772787\n",
      "Average reward:      -62.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02849941500850643\n",
      "Critic loss:         146.90273412068686\n",
      "Average reward:      -61.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024734194730020437\n",
      "Critic loss:         121.42008876800537\n",
      "Average reward:      -57.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02526095310167875\n",
      "Critic loss:         188.51360956827799\n",
      "Average reward:      -61.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02007072115285761\n",
      "Critic loss:         166.30490016937256\n",
      "Average reward:      -59.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028502593012187088\n",
      "Critic loss:         100.46626822153728\n",
      "Average reward:      -57.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.025318058595682185\n",
      "Critic loss:         138.86551157633463\n",
      "Average reward:      -58.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02723832244131093\n",
      "Critic loss:         132.80952962239584\n",
      "Average reward:      -58.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02186091636758647\n",
      "Critic loss:         187.60704612731934\n",
      "Average reward:      -58.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025895191720337607\n",
      "Critic loss:         127.21237468719482\n",
      "Average reward:      -57.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025596170424250886\n",
      "Critic loss:         167.9279063542684\n",
      "Average reward:      -59.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028502163171651773\n",
      "Critic loss:         139.26117070515951\n",
      "Average reward:      -58.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02357113060619061\n",
      "Critic loss:         165.75738938649496\n",
      "Average reward:      -60.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023032191461728264\n",
      "Critic loss:         195.61837927500406\n",
      "Average reward:      -59.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027536282713602606\n",
      "Critic loss:         152.37361208597818\n",
      "Average reward:      -58.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02437104715500027\n",
      "Critic loss:         179.09154224395752\n",
      "Average reward:      -58.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026744588578973588\n",
      "Critic loss:         109.05813535054524\n",
      "Average reward:      -55.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024156010991039995\n",
      "Critic loss:         111.5582405726115\n",
      "Average reward:      -56.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030199820059351623\n",
      "Critic loss:         122.62914594014485\n",
      "Average reward:      -58.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025614246532010537\n",
      "Critic loss:         199.78805351257324\n",
      "Average reward:      -61.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02493078839809944\n",
      "Critic loss:         108.78613535563152\n",
      "Average reward:      -56.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02429952210513875\n",
      "Critic loss:         109.53998724619548\n",
      "Average reward:      -57.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029371506403549574\n",
      "Critic loss:         169.7407086690267\n",
      "Average reward:      -60.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027150124054363307\n",
      "Critic loss:         92.77529970804851\n",
      "Average reward:      -56.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020200078026391566\n",
      "Critic loss:         145.51764933268228\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026074573809940677\n",
      "Critic loss:         84.93637784322102\n",
      "Average reward:      -56.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022393183782696724\n",
      "Critic loss:         115.23625628153484\n",
      "Average reward:      -56.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02396293244479845\n",
      "Critic loss:         113.72172832489014\n",
      "Average reward:      -56.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025018047183645347\n",
      "Critic loss:         119.43784236907959\n",
      "Average reward:      -57.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02830858020267139\n",
      "Critic loss:         100.83363087972005\n",
      "Average reward:      -55.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024023911062007148\n",
      "Critic loss:         207.27045313517252\n",
      "Average reward:      -60.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02281851790030487\n",
      "Critic loss:         128.15518760681152\n",
      "Average reward:      -58.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025440833245132428\n",
      "Critic loss:         161.49919764200845\n",
      "Average reward:      -60.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024644794097791117\n",
      "Critic loss:         136.38483746846518\n",
      "Average reward:      -59.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025321410551744822\n",
      "Critic loss:         186.56307156880698\n",
      "Average reward:      -59.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021924727840087144\n",
      "Critic loss:         111.73953946431477\n",
      "Average reward:      -57.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01847931635954107\n",
      "Critic loss:         169.90327072143555\n",
      "Average reward:      -59.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025370347779244184\n",
      "Critic loss:         75.55404074986775\n",
      "Average reward:      -54.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026331624171386164\n",
      "Critic loss:         118.10804112752278\n",
      "Average reward:      -56.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02632693723232175\n",
      "Critic loss:         116.4358917872111\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023790613845145952\n",
      "Critic loss:         136.78309377034506\n",
      "Average reward:      -58.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026174422780362267\n",
      "Critic loss:         112.61809158325195\n",
      "Average reward:      -56.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02467753953533247\n",
      "Critic loss:         156.90628814697266\n",
      "Average reward:      -58.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025973642244935036\n",
      "Critic loss:         56.62313159306844\n",
      "Average reward:      -53.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028621740793217516\n",
      "Critic loss:         122.27397918701172\n",
      "Average reward:      -56.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.011841635297363004\n",
      "Critic loss:         123.41947205861409\n",
      "Average reward:      -58.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025970871953177266\n",
      "Critic loss:         163.03587563832602\n",
      "Average reward:      -58.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02520713060706233\n",
      "Critic loss:         117.15212154388428\n",
      "Average reward:      -57.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022387146772719763\n",
      "Critic loss:         110.11502838134766\n",
      "Average reward:      -56.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025921034277416766\n",
      "Critic loss:         142.73453330993652\n",
      "Average reward:      -58.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02385793535116439\n",
      "Critic loss:         196.46942011515299\n",
      "Average reward:      -59.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026130036315104615\n",
      "Critic loss:         118.00747013092041\n",
      "Average reward:      -56.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.020072162355063483\n",
      "Critic loss:         100.0480941136678\n",
      "Average reward:      -56.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01962854020530358\n",
      "Critic loss:         108.48953692118327\n",
      "Average reward:      -55.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022938070113013964\n",
      "Critic loss:         104.52470016479492\n",
      "Average reward:      -55.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025798867767055828\n",
      "Critic loss:         127.56374740600586\n",
      "Average reward:      -57.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025073638687899802\n",
      "Critic loss:         150.70192273457846\n",
      "Average reward:      -58.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02454003175565352\n",
      "Critic loss:         100.92570400238037\n",
      "Average reward:      -56.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020690773590710403\n",
      "Critic loss:         80.32797384262085\n",
      "Average reward:      -54.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025604066642699763\n",
      "Critic loss:         96.7776912053426\n",
      "Average reward:      -56.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024964742255785193\n",
      "Critic loss:         133.3431396484375\n",
      "Average reward:      -57.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029240478780896712\n",
      "Critic loss:         105.05575466156006\n",
      "Average reward:      -58.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0264660490793176\n",
      "Critic loss:         132.38012504577637\n",
      "Average reward:      -58.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01513462762037913\n",
      "Critic loss:         119.13118775685628\n",
      "Average reward:      -58.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021760734215301152\n",
      "Critic loss:         135.06431420644125\n",
      "Average reward:      -57.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022961183824615244\n",
      "Critic loss:         83.21529372533162\n",
      "Average reward:      -54.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026375207642558962\n",
      "Critic loss:         166.36733754475912\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025370757735799998\n",
      "Critic loss:         117.36760902404785\n",
      "Average reward:      -57.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019287809293018654\n",
      "Critic loss:         101.3884350458781\n",
      "Average reward:      -55.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.03129002520775733\n",
      "Critic loss:         88.58997217814128\n",
      "Average reward:      -56.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023000668952590786\n",
      "Critic loss:         127.05173397064209\n",
      "Average reward:      -57.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02716130417926858\n",
      "Critic loss:         136.5431753794352\n",
      "Average reward:      -58.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.012744581967126578\n",
      "Critic loss:         124.00338649749756\n",
      "Average reward:      -56.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021495039202515425\n",
      "Critic loss:         194.4009288152059\n",
      "Average reward:      -59.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02669369043239082\n",
      "Critic loss:         89.95490837097168\n",
      "Average reward:      -55.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027920687217071343\n",
      "Critic loss:         101.53844674428304\n",
      "Average reward:      -56.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02252604942865825\n",
      "Critic loss:         118.56369749704997\n",
      "Average reward:      -55.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02564893533902553\n",
      "Critic loss:         84.85389868418376\n",
      "Average reward:      -56.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.029138774785678834\n",
      "Critic loss:         76.33564917246501\n",
      "Average reward:      -55.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02809228177162974\n",
      "Critic loss:         110.31412728627522\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023569473957953353\n",
      "Critic loss:         116.07342433929443\n",
      "Average reward:      -56.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027442221607392032\n",
      "Critic loss:         68.5516489346822\n",
      "Average reward:      -53.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020472329973320786\n",
      "Critic loss:         180.66834195454916\n",
      "Average reward:      -58.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0234717400065468\n",
      "Critic loss:         188.74839973449707\n",
      "Average reward:      -58.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028483797427422058\n",
      "Critic loss:         94.8298552831014\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026113886541376512\n",
      "Critic loss:         143.0270799001058\n",
      "Average reward:      -58.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023470396796862285\n",
      "Critic loss:         152.08636411031088\n",
      "Average reward:      -57.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019105772730351116\n",
      "Critic loss:         97.94234371185303\n",
      "Average reward:      -55.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025316041747525258\n",
      "Critic loss:         147.42799854278564\n",
      "Average reward:      -59.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022996423882432282\n",
      "Critic loss:         150.70892906188965\n",
      "Average reward:      -57.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02754166573868133\n",
      "Critic loss:         79.19839286804199\n",
      "Average reward:      -55.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02652468001663995\n",
      "Critic loss:         100.62698141733806\n",
      "Average reward:      -56.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02411658537251545\n",
      "Critic loss:         111.5933043162028\n",
      "Average reward:      -56.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027633655054766375\n",
      "Critic loss:         130.1334966023763\n",
      "Average reward:      -57.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026362971402704716\n",
      "Critic loss:         127.24784437815349\n",
      "Average reward:      -58.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02197285682874887\n",
      "Critic loss:         77.63337818781535\n",
      "Average reward:      -54.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02675366073405409\n",
      "Critic loss:         128.37695535024008\n",
      "Average reward:      -56.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02720471255937203\n",
      "Critic loss:         122.56217702229817\n",
      "Average reward:      -56.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.02488451896351762\n",
      "Critic loss:         89.23171488444011\n",
      "Average reward:      -56.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02288024560160314\n",
      "Critic loss:         124.54818693796794\n",
      "Average reward:      -56.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025128570559900254\n",
      "Critic loss:         112.57888158162434\n",
      "Average reward:      -56.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019794852356426418\n",
      "Critic loss:         122.71062564849854\n",
      "Average reward:      -57.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024055515590589494\n",
      "Critic loss:         81.21144819259644\n",
      "Average reward:      -54.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020800279899655532\n",
      "Critic loss:         158.38683446248373\n",
      "Average reward:      -57.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024610349525270674\n",
      "Critic loss:         100.3794371287028\n",
      "Average reward:      -56.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022717957928155858\n",
      "Critic loss:         90.70488707224528\n",
      "Average reward:      -55.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01540503436505484\n",
      "Critic loss:         122.82430458068848\n",
      "Average reward:      -56.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023040058207698166\n",
      "Critic loss:         104.38715521494548\n",
      "Average reward:      -57.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02365007201539508\n",
      "Critic loss:         146.8079465230306\n",
      "Average reward:      -58.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.017301518508854013\n",
      "Critic loss:         109.45377286275227\n",
      "Average reward:      -56.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021530084282858297\n",
      "Critic loss:         102.10743649800618\n",
      "Average reward:      -56.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.016018376998545136\n",
      "Critic loss:         143.63346354166666\n",
      "Average reward:      -57.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02214424563862849\n",
      "Critic loss:         181.16272481282553\n",
      "Average reward:      -58.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01927684076751272\n",
      "Critic loss:         133.81817150115967\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023824354706448503\n",
      "Critic loss:         120.65131727854411\n",
      "Average reward:      -57.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028995393658988178\n",
      "Critic loss:         106.84107939402263\n",
      "Average reward:      -57.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02741849401354557\n",
      "Critic loss:         151.02766799926758\n",
      "Average reward:      -60.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021109667726705084\n",
      "Critic loss:         104.33706029256184\n",
      "Average reward:      -56.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.012896768786352672\n",
      "Critic loss:         118.13931465148926\n",
      "Average reward:      -56.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023263120267074555\n",
      "Critic loss:         91.7650105158488\n",
      "Average reward:      -55.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02605573998395509\n",
      "Critic loss:         98.32045682271321\n",
      "Average reward:      -56.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02049841545704112\n",
      "Critic loss:         152.2340291341146\n",
      "Average reward:      -59.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02315065454846869\n",
      "Critic loss:         108.92458788553874\n",
      "Average reward:      -57.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01970547756476056\n",
      "Critic loss:         118.28982988993327\n",
      "Average reward:      -56.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025204152707980636\n",
      "Critic loss:         152.3246924082438\n",
      "Average reward:      -59.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026093278245146696\n",
      "Critic loss:         155.61387221018472\n",
      "Average reward:      -58.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023914367718437763\n",
      "Critic loss:         133.40888595581055\n",
      "Average reward:      -57.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024907541012604877\n",
      "Critic loss:         116.57845846811931\n",
      "Average reward:      -57.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023497234127717093\n",
      "Critic loss:         163.6511433919271\n",
      "Average reward:      -58.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021922924982694287\n",
      "Critic loss:         101.9954662322998\n",
      "Average reward:      -55.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022954229248474196\n",
      "Critic loss:         114.85177580515544\n",
      "Average reward:      -57.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022466243521193974\n",
      "Critic loss:         90.85871458053589\n",
      "Average reward:      -55.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019090830598239943\n",
      "Critic loss:         123.1080691019694\n",
      "Average reward:      -56.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023646928622232128\n",
      "Critic loss:         154.6354662577311\n",
      "Average reward:      -58.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.018412183281422283\n",
      "Critic loss:         166.62977854410806\n",
      "Average reward:      -60.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024608154509526987\n",
      "Critic loss:         158.3930950164795\n",
      "Average reward:      -59.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024646647832317587\n",
      "Critic loss:         134.12299060821533\n",
      "Average reward:      -57.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024111435826246936\n",
      "Critic loss:         128.0669708251953\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021954635943984613\n",
      "Critic loss:         107.6208511988322\n",
      "Average reward:      -56.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026286251852676894\n",
      "Critic loss:         157.68002955118814\n",
      "Average reward:      -58.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022310301283141598\n",
      "Critic loss:         135.50008169809976\n",
      "Average reward:      -57.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02227650417868669\n",
      "Critic loss:         102.88894939422607\n",
      "Average reward:      -55.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022894624727390085\n",
      "Critic loss:         150.9679921468099\n",
      "Average reward:      -58.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02154481586088271\n",
      "Critic loss:         97.44486268361409\n",
      "Average reward:      -55.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.02545408888545353\n",
      "Critic loss:         90.07297039031982\n",
      "Average reward:      -55.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0251851251135425\n",
      "Critic loss:         206.4363644917806\n",
      "Average reward:      -60.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021912226802669466\n",
      "Critic loss:         136.86729780832925\n",
      "Average reward:      -57.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025716181999693315\n",
      "Critic loss:         63.76467227935791\n",
      "Average reward:      -54.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023440701950069826\n",
      "Critic loss:         100.0350383122762\n",
      "Average reward:      -54.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022261918503014993\n",
      "Critic loss:         65.66563892364502\n",
      "Average reward:      -54.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020358929068606813\n",
      "Critic loss:         223.83909924825033\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02018459565503387\n",
      "Critic loss:         137.89441204071045\n",
      "Average reward:      -56.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022679829310315352\n",
      "Critic loss:         189.44605127970377\n",
      "Average reward:      -59.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02348654885281576\n",
      "Critic loss:         121.06292088826497\n",
      "Average reward:      -56.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01900014773127623\n",
      "Critic loss:         134.38676897684732\n",
      "Average reward:      -56.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02425808644814727\n",
      "Critic loss:         149.5792776743571\n",
      "Average reward:      -59.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.018899360091988154\n",
      "Critic loss:         189.54172643025717\n",
      "Average reward:      -60.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.007850563541675607\n",
      "Critic loss:         99.02756150563557\n",
      "Average reward:      -55.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02836659782527325\n",
      "Critic loss:         174.70590496063232\n",
      "Average reward:      -61.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02852229721126302\n",
      "Critic loss:         151.50860404968262\n",
      "Average reward:      -59.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0257545125108057\n",
      "Critic loss:         186.96198495229086\n",
      "Average reward:      -59.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.019622793922356625\n",
      "Critic loss:         171.67712243398032\n",
      "Average reward:      -57.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023083347909656975\n",
      "Critic loss:         64.39131577809651\n",
      "Average reward:      -52.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022653424514525494\n",
      "Critic loss:         154.03393904368082\n",
      "Average reward:      -57.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022878013880169117\n",
      "Critic loss:         203.74244117736816\n",
      "Average reward:      -60.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02589527252591021\n",
      "Critic loss:         126.21490478515625\n",
      "Average reward:      -57.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026518507685977966\n",
      "Critic loss:         97.4087594350179\n",
      "Average reward:      -56.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02466848277375296\n",
      "Critic loss:         97.97630182902019\n",
      "Average reward:      -55.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024093166304131348\n",
      "Critic loss:         93.65195337931316\n",
      "Average reward:      -55.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02767358691683815\n",
      "Critic loss:         188.89144293467203\n",
      "Average reward:      -60.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026033438994393993\n",
      "Critic loss:         165.59238719940186\n",
      "Average reward:      -60.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02548883541021496\n",
      "Critic loss:         83.11986748377483\n",
      "Average reward:      -55.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023859930641871568\n",
      "Critic loss:         95.68781566619873\n",
      "Average reward:      -56.64\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025213906940431723\n",
      "Critic loss:         89.67798169453938\n",
      "Average reward:      -55.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01969958533300087\n",
      "Critic loss:         109.79533545176189\n",
      "Average reward:      -55.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.023048209104066093\n",
      "Critic loss:         95.68889554341634\n",
      "Average reward:      -56.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022422959188891884\n",
      "Critic loss:         103.6241267522176\n",
      "Average reward:      -56.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022524963433776673\n",
      "Critic loss:         126.84981505076091\n",
      "Average reward:      -57.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          0.012567132439774772\n",
      "Critic loss:         138.28610547383627\n",
      "Average reward:      -58.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022378690502894944\n",
      "Critic loss:         243.03026326497397\n",
      "Average reward:      -67.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026583305045884725\n",
      "Critic loss:         190.62235387166342\n",
      "Average reward:      -62.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.028067214298062027\n",
      "Critic loss:         201.55566469828287\n",
      "Average reward:      -62.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026956825395852018\n",
      "Critic loss:         148.61341985066733\n",
      "Average reward:      -59.92\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.030733307231760893\n",
      "Critic loss:         135.694141070048\n",
      "Average reward:      -59.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027072732453234494\n",
      "Critic loss:         186.72531032562256\n",
      "Average reward:      -61.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02961600476798291\n",
      "Critic loss:         121.14310359954834\n",
      "Average reward:      -57.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.0289973332498145\n",
      "Critic loss:         139.07312965393066\n",
      "Average reward:      -60.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024120546095521906\n",
      "Critic loss:         160.74408149719238\n",
      "Average reward:      -58.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021911667766592775\n",
      "Critic loss:         106.25088246663411\n",
      "Average reward:      -56.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024521104952630896\n",
      "Critic loss:         125.02751763661702\n",
      "Average reward:      -58.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss:          -0.020148553429559495\n",
      "Critic loss:         162.10616302490234\n",
      "Average reward:      -58.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024310161747659247\n",
      "Critic loss:         114.50863520304362\n",
      "Average reward:      -57.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02165541706441824\n",
      "Critic loss:         112.2274154027303\n",
      "Average reward:      -58.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025511197784605127\n",
      "Critic loss:         101.33695983886719\n",
      "Average reward:      -55.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025914292957168072\n",
      "Critic loss:         149.08735434214273\n",
      "Average reward:      -57.6\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01623999056998097\n",
      "Critic loss:         133.26881980895996\n",
      "Average reward:      -56.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021254751773085445\n",
      "Critic loss:         81.30015420913696\n",
      "Average reward:      -56.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02538845482437561\n",
      "Critic loss:         88.90333525339763\n",
      "Average reward:      -55.04\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.01967387671660011\n",
      "Critic loss:         181.232271194458\n",
      "Average reward:      -57.52\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.016389482819552843\n",
      "Critic loss:         142.94424072901407\n",
      "Average reward:      -56.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027741574274841696\n",
      "Critic loss:         95.16365496317546\n",
      "Average reward:      -56.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026201546589921538\n",
      "Critic loss:         66.79627831776936\n",
      "Average reward:      -54.84\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02471435639987855\n",
      "Critic loss:         87.25534121195476\n",
      "Average reward:      -55.0\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.018883350525963277\n",
      "Critic loss:         165.4393434524536\n",
      "Average reward:      -57.76\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022336411665188887\n",
      "Critic loss:         92.65974775950114\n",
      "Average reward:      -55.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021379186165480252\n",
      "Critic loss:         90.18442487716675\n",
      "Average reward:      -55.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024338670142848667\n",
      "Critic loss:         136.9439353942871\n",
      "Average reward:      -57.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021081116001975413\n",
      "Critic loss:         160.88980674743652\n",
      "Average reward:      -57.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022651650845849264\n",
      "Critic loss:         139.2002042134603\n",
      "Average reward:      -57.56\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021569713794936735\n",
      "Critic loss:         177.4413595199585\n",
      "Average reward:      -59.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027990129983891165\n",
      "Critic loss:         102.63282044728597\n",
      "Average reward:      -55.68\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02302437559167932\n",
      "Critic loss:         98.21773354212444\n",
      "Average reward:      -54.4\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024088592249124\n",
      "Critic loss:         182.25822575887045\n",
      "Average reward:      -57.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02367464495182503\n",
      "Critic loss:         96.53475793202718\n",
      "Average reward:      -55.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020082196744624525\n",
      "Critic loss:         130.34896183013916\n",
      "Average reward:      -56.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02397054762695916\n",
      "Critic loss:         79.73892402648926\n",
      "Average reward:      -54.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020529915952162508\n",
      "Critic loss:         129.61698818206787\n",
      "Average reward:      -57.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.018899815987121354\n",
      "Critic loss:         90.061594804128\n",
      "Average reward:      -54.48\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02591056648088852\n",
      "Critic loss:         78.73532517751057\n",
      "Average reward:      -55.32\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.026645221669847768\n",
      "Critic loss:         131.16444714864096\n",
      "Average reward:      -56.88\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.016501171092386357\n",
      "Critic loss:         118.2293430964152\n",
      "Average reward:      -54.2\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.020227972825523466\n",
      "Critic loss:         140.10890356699625\n",
      "Average reward:      -57.24\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.022207126845993724\n",
      "Critic loss:         120.89895947774251\n",
      "Average reward:      -57.72\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.018546848269276477\n",
      "Critic loss:         146.65588188171387\n",
      "Average reward:      -56.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02312800755801921\n",
      "Critic loss:         113.16789468129475\n",
      "Average reward:      -56.12\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02582923090449185\n",
      "Critic loss:         84.60162099202473\n",
      "Average reward:      -55.8\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.025147981205615604\n",
      "Critic loss:         134.9942528406779\n",
      "Average reward:      -58.08\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.02669836994027719\n",
      "Critic loss:         149.02386665344238\n",
      "Average reward:      -58.96\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.021743147013088066\n",
      "Critic loss:         130.56568686167398\n",
      "Average reward:      -57.44\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          0.0007957871033189198\n",
      "Critic loss:         124.9069430033366\n",
      "Average reward:      -57.28\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.027100139161727082\n",
      "Critic loss:         154.58493073781332\n",
      "Average reward:      -59.36\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n",
      "Actor loss:          -0.024649990363589797\n",
      "Critic loss:         205.27490901947021\n",
      "Average reward:      -61.16\n",
      "Num episodes:        200\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1833:\n",
      "Process Process-1834:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 194, in reduce_storage\n",
      "    df = multiprocessing.reduction.DupFd(fd)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/reduction.py\", line 191, in DupFd\n",
      "    return resource_sharer.DupFd(fd)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/resource_sharer.py\", line 53, in __init__\n",
      "    self._id = _resource_sharer.register(send, close)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/resource_sharer.py\", line 77, in register\n",
      "    self._start()\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/resource_sharer.py\", line 130, in _start\n",
      "    self._listener = Listener(authkey=process.current_process().authkey)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/connection.py\", line 432, in __init__\n",
      "    address = address or arbitrary_address(family)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/connection.py\", line 76, in arbitrary_address\n",
      "    return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/util.py\", line 114, in get_temp_dir\n",
      "    tempdir = tempfile.mkdtemp(prefix='pymp-')\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8353b51e4faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss_actor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/opensim-rl/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/opensim-rl/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/opensim-rl/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/opensim-rl/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/resource_sharer.py\", line 77, in register\n",
      "    self._start()\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 194, in reduce_storage\n",
      "    df = multiprocessing.reduction.DupFd(fd)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/reduction.py\", line 191, in DupFd\n",
      "    return resource_sharer.DupFd(fd)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/resource_sharer.py\", line 53, in __init__\n",
      "    self._id = _resource_sharer.register(send, close)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/resource_sharer.py\", line 130, in _start\n",
      "    self._listener = Listener(authkey=process.current_process().authkey)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/connection.py\", line 432, in __init__\n",
      "    address = address or arbitrary_address(family)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/connection.py\", line 76, in arbitrary_address\n",
      "    return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/tempfile.py\", line 370, in mkdtemp\n",
      "    _os.mkdir(file, 0o700)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/multiprocessing/util.py\", line 114, in get_temp_dir\n",
      "    tempdir = tempfile.mkdtemp(prefix='pymp-')\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/tempfile.py\", line 360, in mkdtemp\n",
      "    prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/tempfile.py\", line 130, in _sanitize_params\n",
      "    dir = gettempdir()\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/tempfile.py\", line 298, in gettempdir\n",
      "    tempdir = _get_default_tempdir()\n",
      "  File \"/home/agrinchuk/miniconda3/envs/opensim-rl/lib/python3.6/tempfile.py\", line 210, in _get_default_tempdir\n",
      "    fd = _os.open(filename, _bin_openflags, 0o600)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 0\n",
    "avg_reward = 0\n",
    "sum_actor_loss = 0\n",
    "sum_critic_loss = 0\n",
    "\n",
    "actor_losses = []\n",
    "critic_losses = []\n",
    "total_rewards = []\n",
    "episode_rewards = []\n",
    "\n",
    "for epoch in range(1, 10000):\n",
    "    \n",
    "    buffer = BufferDataset(state_shape, batch_size)\n",
    "\n",
    "    while len(buffer) < batch_size:\n",
    "        episode = play_episode(env, algo.actor)\n",
    "        ret, val, adv, log_pi = algo.evaluate_episode(\n",
    "            episode[0], episode[1], episode[2], episode[3])\n",
    "        data = [episode[0], episode[1], episode[2], ret, val, adv, log_pi]\n",
    "        buffer.push_episode(data)\n",
    "        episode_rewards.append(np.sum(episode[3]))\n",
    "        num_episodes += 1\n",
    "    buffer.rescale_advantages()\n",
    "        \n",
    "    sampler = BufferSampler(\n",
    "        buffer=buffer,\n",
    "        num_mini_epochs=num_mini_epochs)\n",
    "    loader = DataLoader(\n",
    "        dataset=buffer,\n",
    "        batch_size=minibatch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        sampler=sampler)\n",
    "        \n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for i, batch in enumerate(loader):\n",
    "        metrics = algo.train(batch)\n",
    "        actor_loss.append(metrics[\"loss_actor\"])\n",
    "        critic_loss.append(metrics[\"loss_critic\"])\n",
    "    sum_actor_loss += np.mean(actor_loss)\n",
    "    sum_critic_loss += np.mean(critic_loss)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        avg_rew = np.mean(episode_rewards)\n",
    "        avg_actor_loss = sum_actor_loss\n",
    "        avg_critic_loss = sum_critic_loss\n",
    "        print (\"Actor loss:         \", avg_actor_loss)\n",
    "        print (\"Critic loss:        \", avg_critic_loss)\n",
    "        print (\"Average reward:     \", avg_rew)\n",
    "        print (\"Num episodes:       \", num_episodes)\n",
    "        print (\"--------------------------------------------\")\n",
    "        actor_losses.append(avg_actor_loss)\n",
    "        critic_losses.append(avg_critic_loss)\n",
    "        total_rewards.append(avg_rew)\n",
    "        sum_actor_loss = 0\n",
    "        sum_critic_loss = 0\n",
    "        episode_rewards = []\n",
    "    num_episodes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f163d67ee80>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(critic_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f163d5db278>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(critic_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensim",
   "language": "python3",
   "name": "opensim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
